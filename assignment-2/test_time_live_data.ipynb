{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"df_train_shuffled(2).csv\")\n",
    "df_noise = pd.read_csv(\"data/cf_train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(value, encoding):\n",
    "    for key, val in encoding.items():\n",
    "        if value == key:\n",
    "            return val\n",
    "\n",
    "class_values_era = list(df.era.unique())\n",
    "class_values_era.sort()\n",
    "class_values_target = list(df.target_10_val.unique())\n",
    "class_values_target.sort()\n",
    "era_encoding = {val: i for i, val in enumerate(class_values_era)}\n",
    "target_encoding = {val: i for i, val in enumerate(class_values_target)}\n",
    "df[\"era\"] = df[\"era\"].apply(encode, args=(era_encoding,))\n",
    "df[\"target_5_val\"] = df[\"target_5_val\"].apply(encode, args=(target_encoding,))\n",
    "df[\"target_10_val\"] = df[\"target_10_val\"].apply(encode, args=(target_encoding,))\n",
    "\n",
    "df_noise[\"era\"] = df_noise[\"era\"].apply(encode, args=(era_encoding,))\n",
    "df_noise[\"target_5_val\"] = df_noise[\"target_5_val\"].apply(encode, args=(target_encoding,))\n",
    "df_noise[\"target_10_val\"] = df_noise[\"target_10_val\"].apply(encode, args=(target_encoding,))\n",
    "\n",
    "dataset = df\n",
    "target_column = \"target_10_val\"\n",
    "output_classes = 5\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_n_val</th>\n",
       "      <th>High_n_val</th>\n",
       "      <th>Low_n_val</th>\n",
       "      <th>Close_n_val</th>\n",
       "      <th>Volume_n_val</th>\n",
       "      <th>SMA_10_val</th>\n",
       "      <th>SMA_20_val</th>\n",
       "      <th>CMO_14_val</th>\n",
       "      <th>High_n-Low_n_val</th>\n",
       "      <th>Open_n-Close_n_val</th>\n",
       "      <th>...</th>\n",
       "      <th>High_n-Low_n_changelen_val</th>\n",
       "      <th>Open_n-Close_n_changelen_val</th>\n",
       "      <th>SMA_20-SMA_10_changelen_val</th>\n",
       "      <th>Close_n_slope_3_changelen_val</th>\n",
       "      <th>Close_n_slope_5_changelen_val</th>\n",
       "      <th>Close_n_slope_10_changelen_val</th>\n",
       "      <th>row_num</th>\n",
       "      <th>era</th>\n",
       "      <th>target_10_val</th>\n",
       "      <th>target_5_val</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>100</td>\n",
       "      <td>118</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>24</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>83</td>\n",
       "      <td>57</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>101</td>\n",
       "      <td>109</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>101</td>\n",
       "      <td>92</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175122</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175123</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>79</td>\n",
       "      <td>131</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175124</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>65</td>\n",
       "      <td>118</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175125</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>115</td>\n",
       "      <td>19</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175126</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>87</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175127 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open_n_val  High_n_val  Low_n_val  Close_n_val  Volume_n_val  \\\n",
       "0             0.75        0.75       0.75         0.75          0.25   \n",
       "1             0.25        0.25       0.25         0.25          0.25   \n",
       "2             0.75        0.75       0.75         0.50          0.50   \n",
       "3             0.25        0.25       0.25         0.25          0.75   \n",
       "4             0.00        0.00       0.00         0.00          0.50   \n",
       "...            ...         ...        ...          ...           ...   \n",
       "175122        0.75        0.75       0.75         0.75          0.75   \n",
       "175123        0.75        0.75       0.75         0.75          0.75   \n",
       "175124        0.50        0.50       0.50         0.50          0.00   \n",
       "175125        0.25        0.25       0.25         0.25          0.50   \n",
       "175126        0.25        0.25       0.25         0.25          0.50   \n",
       "\n",
       "        SMA_10_val  SMA_20_val  CMO_14_val  High_n-Low_n_val  \\\n",
       "0             1.00        1.00        0.50              0.25   \n",
       "1             0.50        0.75        0.00              0.25   \n",
       "2             0.50        0.25        1.00              0.75   \n",
       "3             0.25        0.25        0.75              0.50   \n",
       "4             0.00        0.00        0.25              0.50   \n",
       "...            ...         ...         ...               ...   \n",
       "175122        1.00        1.00        0.00              0.75   \n",
       "175123        0.25        0.00        1.00              0.75   \n",
       "175124        0.50        0.25        0.75              0.00   \n",
       "175125        0.25        0.25        0.25              0.50   \n",
       "175126        0.00        0.25        0.00              0.25   \n",
       "\n",
       "        Open_n-Close_n_val  ...  High_n-Low_n_changelen_val  \\\n",
       "0                     0.25  ...                        0.75   \n",
       "1                     1.00  ...                        0.00   \n",
       "2                     1.00  ...                        0.50   \n",
       "3                     0.00  ...                        0.50   \n",
       "4                     1.00  ...                        0.75   \n",
       "...                    ...  ...                         ...   \n",
       "175122                1.00  ...                        0.75   \n",
       "175123                1.00  ...                        0.00   \n",
       "175124                0.25  ...                        0.50   \n",
       "175125                0.75  ...                        0.75   \n",
       "175126                0.50  ...                        0.75   \n",
       "\n",
       "        Open_n-Close_n_changelen_val  SMA_20-SMA_10_changelen_val  \\\n",
       "0                               0.25                         0.50   \n",
       "1                               0.50                         1.00   \n",
       "2                               0.50                         0.25   \n",
       "3                               0.25                         0.25   \n",
       "4                               0.50                         0.00   \n",
       "...                              ...                          ...   \n",
       "175122                          0.50                         1.00   \n",
       "175123                          0.25                         0.25   \n",
       "175124                          0.25                         0.00   \n",
       "175125                          0.50                         0.25   \n",
       "175126                          0.25                         0.00   \n",
       "\n",
       "        Close_n_slope_3_changelen_val  Close_n_slope_5_changelen_val  \\\n",
       "0                                0.75                           1.00   \n",
       "1                                1.00                           0.75   \n",
       "2                                0.50                           0.50   \n",
       "3                                1.00                           0.75   \n",
       "4                                0.00                           0.50   \n",
       "...                               ...                            ...   \n",
       "175122                           0.00                           0.00   \n",
       "175123                           0.25                           0.25   \n",
       "175124                           0.25                           1.00   \n",
       "175125                           0.50                           0.50   \n",
       "175126                           0.00                           0.00   \n",
       "\n",
       "        Close_n_slope_10_changelen_val  row_num  era  target_10_val  \\\n",
       "0                                 0.50      100  118              3   \n",
       "1                                 0.75       24    4              2   \n",
       "2                                 0.50       83   57              2   \n",
       "3                                 1.00      101  109              4   \n",
       "4                                 0.50      101   92              2   \n",
       "...                                ...      ...  ...            ...   \n",
       "175122                            0.00       31   37              2   \n",
       "175123                            0.25       79  131              2   \n",
       "175124                            0.75       65  118              2   \n",
       "175125                            0.50      115   19              2   \n",
       "175126                            0.75       87   25              1   \n",
       "\n",
       "        target_5_val  \n",
       "0                  2  \n",
       "1                  1  \n",
       "2                  2  \n",
       "3                  3  \n",
       "4                  2  \n",
       "...              ...  \n",
       "175122             2  \n",
       "175123             2  \n",
       "175124             3  \n",
       "175125             3  \n",
       "175126             1  \n",
       "\n",
       "[175127 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_n_val</th>\n",
       "      <th>High_n_val</th>\n",
       "      <th>Low_n_val</th>\n",
       "      <th>Close_n_val</th>\n",
       "      <th>Volume_n_val</th>\n",
       "      <th>SMA_10_val</th>\n",
       "      <th>SMA_20_val</th>\n",
       "      <th>CMO_14_val</th>\n",
       "      <th>High_n-Low_n_val</th>\n",
       "      <th>Open_n-Close_n_val</th>\n",
       "      <th>...</th>\n",
       "      <th>Close_n_changelen_val</th>\n",
       "      <th>High_n-Low_n_changelen_val</th>\n",
       "      <th>Open_n-Close_n_changelen_val</th>\n",
       "      <th>SMA_20-SMA_10_changelen_val</th>\n",
       "      <th>Close_n_slope_3_changelen_val</th>\n",
       "      <th>Close_n_slope_5_changelen_val</th>\n",
       "      <th>Close_n_slope_10_changelen_val</th>\n",
       "      <th>row_num</th>\n",
       "      <th>target_10_val</th>\n",
       "      <th>era</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>100</td>\n",
       "      <td>3</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>101</td>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175122</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>31</td>\n",
       "      <td>2</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175123</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175124</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>65</td>\n",
       "      <td>2</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175125</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>115</td>\n",
       "      <td>2</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175126</th>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>87</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>175127 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Open_n_val  High_n_val  Low_n_val  Close_n_val  Volume_n_val  \\\n",
       "0             0.75        0.75       0.75         0.75          0.25   \n",
       "1             0.25        0.25       0.25         0.25          0.25   \n",
       "2             0.75        0.75       0.75         0.50          0.50   \n",
       "3             0.25        0.25       0.25         0.25          0.75   \n",
       "4             0.00        0.00       0.00         0.00          0.50   \n",
       "...            ...         ...        ...          ...           ...   \n",
       "175122        0.75        0.75       0.75         0.75          0.75   \n",
       "175123        0.75        0.75       0.75         0.75          0.75   \n",
       "175124        0.50        0.50       0.50         0.50          0.00   \n",
       "175125        0.25        0.25       0.25         0.25          0.50   \n",
       "175126        0.25        0.25       0.25         0.25          0.50   \n",
       "\n",
       "        SMA_10_val  SMA_20_val  CMO_14_val  High_n-Low_n_val  \\\n",
       "0             1.00        1.00        0.50              0.25   \n",
       "1             0.50        0.75        0.00              0.25   \n",
       "2             0.50        0.25        1.00              0.75   \n",
       "3             0.25        0.25        0.75              0.50   \n",
       "4             0.00        0.00        0.25              0.50   \n",
       "...            ...         ...         ...               ...   \n",
       "175122        1.00        1.00        0.00              0.75   \n",
       "175123        0.25        0.00        1.00              0.75   \n",
       "175124        0.50        0.25        0.75              0.00   \n",
       "175125        0.25        0.25        0.25              0.50   \n",
       "175126        0.00        0.25        0.00              0.25   \n",
       "\n",
       "        Open_n-Close_n_val  ...  Close_n_changelen_val  \\\n",
       "0                     0.25  ...                   1.00   \n",
       "1                     1.00  ...                   0.25   \n",
       "2                     1.00  ...                   0.50   \n",
       "3                     0.00  ...                   1.00   \n",
       "4                     1.00  ...                   0.50   \n",
       "...                    ...  ...                    ...   \n",
       "175122                1.00  ...                   0.00   \n",
       "175123                1.00  ...                   0.25   \n",
       "175124                0.25  ...                   0.75   \n",
       "175125                0.75  ...                   0.50   \n",
       "175126                0.50  ...                   0.75   \n",
       "\n",
       "        High_n-Low_n_changelen_val  Open_n-Close_n_changelen_val  \\\n",
       "0                             0.75                          0.25   \n",
       "1                             0.00                          0.50   \n",
       "2                             0.50                          0.50   \n",
       "3                             0.50                          0.25   \n",
       "4                             0.75                          0.50   \n",
       "...                            ...                           ...   \n",
       "175122                        0.75                          0.50   \n",
       "175123                        0.00                          0.25   \n",
       "175124                        0.50                          0.25   \n",
       "175125                        0.75                          0.50   \n",
       "175126                        0.75                          0.25   \n",
       "\n",
       "        SMA_20-SMA_10_changelen_val  Close_n_slope_3_changelen_val  \\\n",
       "0                              0.50                           0.75   \n",
       "1                              1.00                           1.00   \n",
       "2                              0.25                           0.50   \n",
       "3                              0.25                           1.00   \n",
       "4                              0.00                           0.00   \n",
       "...                             ...                            ...   \n",
       "175122                         1.00                           0.00   \n",
       "175123                         0.25                           0.25   \n",
       "175124                         0.00                           0.25   \n",
       "175125                         0.25                           0.50   \n",
       "175126                         0.00                           0.00   \n",
       "\n",
       "        Close_n_slope_5_changelen_val  Close_n_slope_10_changelen_val  \\\n",
       "0                                1.00                            0.50   \n",
       "1                                0.75                            0.75   \n",
       "2                                0.50                            0.50   \n",
       "3                                0.75                            1.00   \n",
       "4                                0.50                            0.50   \n",
       "...                               ...                             ...   \n",
       "175122                           0.00                            0.00   \n",
       "175123                           0.25                            0.25   \n",
       "175124                           1.00                            0.75   \n",
       "175125                           0.50                            0.50   \n",
       "175126                           0.00                            0.75   \n",
       "\n",
       "        row_num  target_10_val  era  \n",
       "0           100              3  118  \n",
       "1            24              2    4  \n",
       "2            83              2   57  \n",
       "3           101              4  109  \n",
       "4           101              2   92  \n",
       "...         ...            ...  ...  \n",
       "175122       31              2   37  \n",
       "175123       79              2  131  \n",
       "175124       65              2  118  \n",
       "175125      115              2   19  \n",
       "175126       87              1   25  \n",
       "\n",
       "[175127 rows x 27 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove target_5_val, sigma from the dataset\n",
    "new_dataset = dataset.drop(columns=[\"target_5_val\"])\n",
    "era = new_dataset.pop(\"era\")\n",
    "target = new_dataset.pop(target_column)\n",
    "new_dataset[target_column] = target\n",
    "new_dataset[\"era\"] = era\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, X,y):\n",
    "        self.X =X\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(new_dataset.drop(columns=[target_column,'era','row_num']).values, new_dataset[target_column].values)\n",
    "train_loader = DataLoader(train_dataset, batch_size=256, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test_data\n",
    "df_test = pd.read_csv(\"data/cf_test_no_noise.csv\")\n",
    "df_test_noise = pd.read_csv(\"data/cf_test.csv\")\n",
    "\n",
    "df_test[\"era\"] = df_test[\"era\"].apply(encode, args=(era_encoding,))\n",
    "df_test[\"target_5_val\"] = df_test[\"target_5_val\"].apply(encode, args=(target_encoding,))\n",
    "df_test[\"target_10_val\"] = df_test[\"target_10_val\"].apply(encode, args=(target_encoding,))\n",
    "df_test_noise[\"era\"] = df_test_noise[\"era\"].apply(encode, args=(era_encoding,))\n",
    "df_test_noise[\"target_5_val\"] = df_test_noise[\"target_5_val\"].apply(encode, args=(target_encoding,))\n",
    "df_test_noise[\"target_10_val\"] = df_test_noise[\"target_10_val\"].apply(encode, args=(target_encoding,))\n",
    "\n",
    "test_set = df_test\n",
    "target_column = \"target_10_val\"\n",
    "output_classes = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_n_val</th>\n",
       "      <th>High_n_val</th>\n",
       "      <th>Low_n_val</th>\n",
       "      <th>Close_n_val</th>\n",
       "      <th>Volume_n_val</th>\n",
       "      <th>SMA_10_val</th>\n",
       "      <th>SMA_20_val</th>\n",
       "      <th>CMO_14_val</th>\n",
       "      <th>High_n-Low_n_val</th>\n",
       "      <th>Open_n-Close_n_val</th>\n",
       "      <th>...</th>\n",
       "      <th>Open_n-Close_n_changelen_val</th>\n",
       "      <th>SMA_20-SMA_10_changelen_val</th>\n",
       "      <th>Close_n_slope_3_changelen_val</th>\n",
       "      <th>Close_n_slope_5_changelen_val</th>\n",
       "      <th>Close_n_slope_10_changelen_val</th>\n",
       "      <th>row_num</th>\n",
       "      <th>day</th>\n",
       "      <th>day_no</th>\n",
       "      <th>target_10_val</th>\n",
       "      <th>era</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>75</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>76</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>77</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>78</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>79</td>\n",
       "      <td>555</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62395</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>135</td>\n",
       "      <td>550</td>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62396</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>136</td>\n",
       "      <td>550</td>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62397</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>137</td>\n",
       "      <td>550</td>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62398</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>138</td>\n",
       "      <td>550</td>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62399</th>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>139</td>\n",
       "      <td>550</td>\n",
       "      <td>959</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>62400 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Open_n_val  High_n_val  Low_n_val  Close_n_val  Volume_n_val  \\\n",
       "0            0.50        0.50       0.50         0.50           0.0   \n",
       "1            0.50        0.50       0.50         0.50           0.0   \n",
       "2            0.50        0.50       0.50         0.50           0.0   \n",
       "3            0.50        0.50       0.50         0.75           0.0   \n",
       "4            0.75        0.75       0.75         0.75           0.0   \n",
       "...           ...         ...        ...          ...           ...   \n",
       "62395        1.00        1.00       1.00         1.00           0.0   \n",
       "62396        1.00        1.00       1.00         1.00           0.0   \n",
       "62397        1.00        1.00       1.00         1.00           0.0   \n",
       "62398        1.00        1.00       1.00         1.00           0.0   \n",
       "62399        1.00        1.00       1.00         1.00           0.0   \n",
       "\n",
       "       SMA_10_val  SMA_20_val  CMO_14_val  High_n-Low_n_val  \\\n",
       "0            0.75        0.75        0.25              0.25   \n",
       "1            0.50        0.75        0.25              0.25   \n",
       "2            0.50        0.75        0.50              0.25   \n",
       "3            0.50        0.75        0.50              0.25   \n",
       "4            0.50        0.75        0.50              0.25   \n",
       "...           ...         ...         ...               ...   \n",
       "62395        1.00        1.00        0.25              0.25   \n",
       "62396        1.00        1.00        0.25              0.25   \n",
       "62397        1.00        1.00        0.00              0.25   \n",
       "62398        1.00        1.00        0.00              0.25   \n",
       "62399        1.00        1.00        0.00              0.25   \n",
       "\n",
       "       Open_n-Close_n_val  ...  Open_n-Close_n_changelen_val  \\\n",
       "0                     0.0  ...                          0.50   \n",
       "1                     0.0  ...                          0.75   \n",
       "2                     0.0  ...                          0.75   \n",
       "3                     0.0  ...                          0.75   \n",
       "4                     0.0  ...                          0.75   \n",
       "...                   ...  ...                           ...   \n",
       "62395                 1.0  ...                          1.00   \n",
       "62396                 1.0  ...                          1.00   \n",
       "62397                 1.0  ...                          1.00   \n",
       "62398                 1.0  ...                          1.00   \n",
       "62399                 1.0  ...                          1.00   \n",
       "\n",
       "       SMA_20-SMA_10_changelen_val  Close_n_slope_3_changelen_val  \\\n",
       "0                             1.00                           0.50   \n",
       "1                             1.00                           0.75   \n",
       "2                             0.50                           0.75   \n",
       "3                             0.50                           0.75   \n",
       "4                             0.25                           0.50   \n",
       "...                            ...                            ...   \n",
       "62395                         1.00                           0.00   \n",
       "62396                         1.00                           0.00   \n",
       "62397                         1.00                           0.00   \n",
       "62398                         1.00                           0.00   \n",
       "62399                         1.00                           0.00   \n",
       "\n",
       "       Close_n_slope_5_changelen_val  Close_n_slope_10_changelen_val  row_num  \\\n",
       "0                               0.75                            0.50       75   \n",
       "1                               0.75                            0.75       76   \n",
       "2                               0.75                            0.75       77   \n",
       "3                               0.75                            0.75       78   \n",
       "4                               0.75                            0.75       79   \n",
       "...                              ...                             ...      ...   \n",
       "62395                           0.00                            0.00      135   \n",
       "62396                           0.00                            0.00      136   \n",
       "62397                           0.00                            0.00      137   \n",
       "62398                           0.00                            0.00      138   \n",
       "62399                           0.00                            0.00      139   \n",
       "\n",
       "       day  day_no  target_10_val  era  \n",
       "0      555       0              4  NaN  \n",
       "1      555       0              4  NaN  \n",
       "2      555       0              4  NaN  \n",
       "3      555       0              4  NaN  \n",
       "4      555       0              4  NaN  \n",
       "...    ...     ...            ...  ...  \n",
       "62395  550     959              0  NaN  \n",
       "62396  550     959              0  NaN  \n",
       "62397  550     959              0  NaN  \n",
       "62398  550     959              0  NaN  \n",
       "62399  550     959              0  NaN  \n",
       "\n",
       "[62400 rows x 29 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test_dataset= test_set.drop(columns=[\"target_5_val\", \"sigma\"])\n",
    "era = new_test_dataset.pop(\"era\")\n",
    "target = new_test_dataset.pop(target_column)\n",
    "new_test_dataset[target_column] = target\n",
    "new_test_dataset[\"era\"] = era\n",
    "new_test_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(new_test_dataset.drop(columns=[target_column,'era','row_num','day','day_no']).values, new_test_dataset[target_column].values)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.5000, 0.5000, 0.5000, 0.5000, 0.0000, 0.7500, 0.7500, 0.2500, 0.2500,\n",
       "          0.0000, 0.7500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.2500, 0.5000,\n",
       "          0.0000, 0.5000, 1.0000, 0.5000, 0.7500, 0.5000]], dtype=torch.float64),\n",
       " tensor([4])]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(test_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "class TTA(nn.Module):\n",
    "    def __init__(self, input_size, classification_output_size,auxiliary_output_size):\n",
    "        super(TTA, self).__init__()\n",
    "        self.NAL_layers = nn.Sequential(\n",
    "            nn.Linear(classification_output_size, 1),            \n",
    "        )\n",
    "\n",
    "        self.shared_layers = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 96),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(96, 64),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.prediction_branch = nn.Sequential(\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, classification_output_size)\n",
    "        )\n",
    "        self.auxiliary_branch = nn.Sequential(\n",
    "            nn.Linear(64, auxiliary_output_size),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(24, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, auxiliary_output_size)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.shared_layers(x)\n",
    "        # get output from second to last layer in prediction branch\n",
    "        nal_in = self.prediction_branch(x)\n",
    "        nal_out = torch.sigmoid(self.NAL_layers(nal_in)).to(torch.float64)\n",
    "\n",
    "        return (self.prediction_branch(x)), self.auxiliary_branch(x), nal_out\n",
    "\n",
    "class NoiseAttentionLoss(nn.Module):\n",
    "    def __init__(self, lambda_=50):\n",
    "        super(NoiseAttentionLoss, self).__init__()\n",
    "        self.lambda_ = lambda_\n",
    "\n",
    "    def forward(self, logits, y, tau):\n",
    "        y = F.one_hot(y, output_classes).to(torch.float64)\n",
    "        perceptual = tau.squeeze(1) * (logits.t() - y.t()) + y.t()\n",
    "        attention_term = torch.matmul(y, torch.log(perceptual + 1e-5))\n",
    "        attention_term = attention_term.diag()\n",
    "        boost_term = torch.log(tau + 1e-5) * self.lambda_\n",
    "\n",
    "        attention_term = -torch.mean(attention_term)\n",
    "        boost_term = -torch.mean(boost_term)\n",
    "\n",
    "        return attention_term + boost_term\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef55a047327f44a383bf86e041d5e909",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 10.34971768652352 Accuracy: 0.20620388368771816\n",
      "Epoch 1 Loss: 2.620767365687869 Accuracy: 0.21670079934941286\n",
      "Epoch 2 Loss: 2.4781060167299236 Accuracy: 0.2338114388289432\n",
      "Epoch 3 Loss: 2.4516293424396602 Accuracy: 0.2404169807204062\n",
      "Epoch 4 Loss: 2.4219000846446628 Accuracy: 0.24263527451602665\n",
      "Epoch 5 Loss: 2.4047906183552885 Accuracy: 0.24324048913043478\n",
      "Epoch 6 Loss: 2.3988896388811938 Accuracy: 0.243423714693748\n",
      "Epoch 7 Loss: 2.393595149614829 Accuracy: 0.24454290304665188\n",
      "Epoch 8 Loss: 2.389062963934018 Accuracy: 0.2464624325610917\n",
      "Epoch 9 Loss: 2.383708967260806 Accuracy: 0.24900230085687083\n",
      "Epoch 10 Loss: 2.3810343060603727 Accuracy: 0.25098827753094255\n",
      "Epoch 11 Loss: 2.3786501006915857 Accuracy: 0.25580470485560136\n",
      "Epoch 12 Loss: 2.377344334979839 Accuracy: 0.26145370517296096\n",
      "Epoch 13 Loss: 2.3745540359758848 Accuracy: 0.2678876745477626\n",
      "Epoch 14 Loss: 2.371615406908829 Accuracy: 0.2707682085052364\n",
      "Epoch 15 Loss: 2.3643838219490942 Accuracy: 0.2775606950174548\n",
      "Epoch 16 Loss: 2.3580126637312064 Accuracy: 0.27899476356712155\n",
      "Epoch 17 Loss: 2.354235610501279 Accuracy: 0.2813085131704221\n",
      "Epoch 18 Loss: 2.3511720703425554 Accuracy: 0.28274431728022853\n",
      "Epoch 19 Loss: 2.348117870570831 Accuracy: 0.28228241034592194\n"
     ]
    }
   ],
   "source": [
    "# train the model on Train data this is not test time training yet\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = TTA(input_size=24, classification_output_size=5, auxiliary_output_size=24)\n",
    "model.cuda() \n",
    "# classification_criterion = nn.CrossEntropyLoss()\n",
    "classification_criterion = NoiseAttentionLoss()\n",
    "auxiliary_criterion = nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "bagging_percent = 0.9\n",
    "\n",
    "\n",
    "epochs = 20\n",
    "losses = []\n",
    "predictions = []\n",
    "accuracy = []\n",
    "for epoch in tqdm(range(epochs)):\n",
    "    # loop = tqdm(train_loader, leave=True)\n",
    "    epoch_acc=[]\n",
    "    epoch_loss=[]\n",
    "    for batch,(X, y) in enumerate(train_loader):\n",
    "        X, y = X.cuda().float(), y.cuda().long()\n",
    "        \n",
    "        # # mask 5 columns in X\n",
    "        # mask = torch.randint(0, 27, (5,))\n",
    "        # X[:, mask] = 0\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        prediction_logits, auxiliary,tau = model(X)\n",
    "        # print(tau)\n",
    "        prediction_softmax = F.softmax(prediction_logits, dim=1).to(torch.float64)\n",
    "        prediction = torch.argmax(prediction_softmax, dim=1)\n",
    "\n",
    "        loss1 = classification_criterion(prediction_softmax, y,tau)\n",
    "        # print(prediction_logits)\n",
    "        loss2 = auxiliary_criterion(auxiliary, X)\n",
    "        # print(loss1.item(), loss2.item()    )\n",
    "        accuracy_batch = (prediction == y).sum().item() / len(y)\n",
    "        epoch_acc.append(accuracy_batch)\n",
    "\n",
    "        loss = loss1 + loss2\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # losses.append(loss.item())\n",
    "        epoch_loss.append(loss.item())\n",
    "        predictions.append(prediction)\n",
    "        # break\n",
    "        # if batch == bagging_percent * len(train_loader):\n",
    "        #     break\n",
    "    accuracy.append(np.mean(epoch_acc))\n",
    "    losses.append(np.mean(epoch_loss))\n",
    "    print(f\"Epoch {epoch} Loss: {np.mean(epoch_loss)} Accuracy: {np.mean(epoch_acc)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAh8AAAGzCAYAAACPa3XZAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAwNElEQVR4nO3df3RU9Z3/8dedmWQSYjITkF8p4acKiuCqVYpSaxVR1lro9mh12YpYa9diW7ZqlXMWQV0bf3R7XF0Psq0CrVVrd4v2a1UKrOCqgCC4VdpFUIqx/LKUTEJCJsnM5/tHcicz+T2Ze+8kmefjnDnO3PuZez831zm+fN/P/VzLGGMEAADgEV+2OwAAAHIL4QMAAHiK8AEAADxF+AAAAJ4ifAAAAE8RPgAAgKcIHwAAwFOEDwAA4CnCBwAA8BThAwAAeIrwASAtq1atkmVZ2r59e7a7AqCfInwAAABPET4AAICnCB8AHLdz507Nnj1bJSUlOumkk3TppZdqy5YtKW0aGxt1zz336NRTT1VBQYGGDBmiGTNmaN26dYk2hw4d0oIFCzRq1CgFg0GNHDlSc+bM0Z/+9CePjwiAkwLZ7gCAgWXXrl36/Oc/r5KSEv3gBz9QXl6eVqxYoYsvvlibNm3StGnTJEnLli1TRUWFbrrpJp1//vmqrq7W9u3btWPHDl122WWSpK9+9avatWuXvvOd72js2LE6cuSI1q1bp48//lhjx47N4lECyIRljDHZ7gSA/mPVqlVasGCBtm3bps9+9rPt1n/lK1/Ryy+/rD/+8Y8aP368JOngwYOaOHGizj77bG3atEmS9Dd/8zcaNWqUXnrppQ73U1VVpdLSUj388MO6/fbb3TsgAJ7jsgsAx8RiMf3ud7/T3LlzE8FDkkaOHKm///u/1xtvvKHq6mpJUjgc1q5du7Rnz54Ot1VYWKj8/Hxt3LhRx44d86T/ALxB+ADgmE8//VR1dXWaOHFiu3Wnn3664vG4KisrJUn33nuvqqqqdNppp2nKlCm644479Pvf/z7RPhgM6sEHH9Qrr7yi4cOH66KLLtJDDz2kQ4cOeXY8ANxB+ACQFRdddJE+/PBDPfXUUzrzzDP105/+VOecc45++tOfJtosWrRIH3zwgSoqKlRQUKAlS5bo9NNP186dO7PYcwCZInwAcMzQoUM1aNAg7d69u926//u//5PP51N5eXli2eDBg7VgwQI9++yzqqys1NSpU7Vs2bKU702YMEG33Xabfve73+n9999XQ0OD/vVf/9XtQwHgIsIHAMf4/X7NmjVLL774YsrtsIcPH9YzzzyjGTNmqKSkRJJ09OjRlO+edNJJOuWUUxSNRiVJdXV1qq+vT2kzYcIEFRcXJ9oA6J+41RZArzz11FN69dVX2y1ftmyZ1q1bpxkzZujb3/62AoGAVqxYoWg0qoceeijR7owzztDFF1+sc889V4MHD9b27dv1n//5n7r11lslSR988IEuvfRSXXPNNTrjjDMUCAS0Zs0aHT58WNdee61nxwnAedxqCyAt9q22namsrNSnn36qxYsX680331Q8Hte0adN0//33a/r06Yl2999/v37zm9/ogw8+UDQa1ZgxY/T1r39dd9xxh/Ly8nT06FEtXbpUGzZsUGVlpQKBgCZNmqTbbrtNV199tReHCsAlhA8AAOApxnwAAABPET4AAICnCB8AAMBThA8AAOApwgcAAPAU4QMAAHiqz00yFo/HdeDAARUXF8uyrGx3BwAA9IAxRjU1NSorK5PP13Vto8+FjwMHDqQ8+wEAAPQflZWVGjVqVJdt+lz4KC4ultTcefsZEAAAoG+rrq5WeXl54r/jXelz4cO+1FJSUkL4AACgn+nJkAkGnAIAAE8RPgAAgKcIHwAAwFOEDwAA4CnCBwAA8BThAwAAeIrwAQAAPEX4AAAAniJ8AAAATxE+AACApwgfAADAU4QPAADgqT73YDm3HK6u11Nv7JMsafHs07PdHQAAclbOVD6OR5u04vWP9MzWj7PdFQAAclrOhI9wYZ4kqaa+SU2xeJZ7AwBA7sqZ8BFqCR+SVHWiMYs9AQAgt+VM+Aj4fSopaB7iUlVH+AAAIFtyJnxIUnhQviSpqq4hyz0BACB35VT4KB3UfOnlGJUPAACyJqfCB5UPAACyL6fCh135YMwHAADZk1Phw658HKPyAQBA1uRY+GDMBwAA2ZZT4aO0pfIROUHlAwCAbEk7fLz++uu66qqrVFZWJsuy9MILL6SsN8bo7rvv1siRI1VYWKiZM2dqz549TvU3I4nKRy2VDwAAsiXt8FFbW6uzzjpLjz/+eIfrH3roIT366KN64okntHXrVhUVFenyyy9XfX19xp3NFGM+AADIvrSfajt79mzNnj27w3XGGD3yyCP653/+Z82ZM0eS9LOf/UzDhw/XCy+8oGuvvTaz3mbIvtslwvTqAABkjaNjPvbt26dDhw5p5syZiWWhUEjTpk3T5s2bO/xONBpVdXV1ysstpVQ+AADIOkfDx6FDhyRJw4cPT1k+fPjwxLq2KioqFAqFEq/y8nInu5Qi1FL5qG+Mq74x5tp+AABA57J+t8vixYsViUQSr8rKStf2VRwMKOCzJFH9AAAgWxwNHyNGjJAkHT58OGX54cOHE+vaCgaDKikpSXm5xbKsxB0vzHIKAEB2OBo+xo0bpxEjRmjDhg2JZdXV1dq6daumT5/u5K56jTteAADIrrTvdjl+/Lj27t2b+Lxv3z69++67Gjx4sEaPHq1FixbpX/7lX3Tqqadq3LhxWrJkicrKyjR37lwn+91r4UIqHwAAZFPa4WP79u364he/mPj8/e9/X5I0f/58rVq1Sj/4wQ9UW1urm2++WVVVVZoxY4ZeffVVFRQUONfrDFD5AAAgu9IOHxdffLGMMZ2utyxL9957r+69996MOuYWnmwLAEB2Zf1uF6+1Djil8gEAQDbkYPiwL7tQ+QAAIBtyLnzYs5xy2QUAgOzIwfDBZRcAALIp58KHPcU6d7sAAJAdORc+uOwCAEB25W74ONHY5S3DAADAHTkXPuxbbWNxo5poU5Z7AwBA7sm58FGQ51dBXvNhV9Vy6QUAAK/lXPiQki+9MOgUAACv5WT4YKIxAACyJzfDRyFzfQAAkC05GT5Ki1rm+qglfAAA4LWcDB/hpNttAQCAt3IzfCQuuxA+AADwWk6Gj9LEgFMuuwAA4LWcDB/hQVQ+AADIlpwMH63Pd6HyAQCA13IyfIQTT7al8gEAgNdyNHww5gMAgGzJyfBR2lL5qKlvUlMsnuXeAACQW3IyfIRabrWVpAhzfQAA4KmcDB8Bv0/FBQFJjPsAAMBrORk+JO54AQAgW3I4fDDXBwAA2ZCz4SPEHS8AAGRFzoYPKh8AAGRHDocP+8m2VD4AAPBSzoYPZjkFACA7cjd8FNqXXah8AADgpZwNH6VFLQNOa6l8AADgJVfCR01NjRYtWqQxY8aosLBQF1xwgbZt2+bGrnotnBjzQfgAAMBLroSPm266SevWrdPPf/5zvffee5o1a5ZmzpypP//5z27srle47AIAQHY4Hj5OnDih//qv/9JDDz2kiy66SKeccoqWLVumU045RcuXL3d6d71WyjwfAABkRcDpDTY1NSkWi6mgoCBleWFhod5444127aPRqKLRaOJzdXW1013qULioufJR3xhXfWNMBXl+T/YLAECuc7zyUVxcrOnTp+u+++7TgQMHFIvF9PTTT2vz5s06ePBgu/YVFRUKhUKJV3l5udNd6rifwYD8PksSE40BAOAlV8Z8/PznP5cxRp/5zGcUDAb16KOP6rrrrpPP1353ixcvViQSSbwqKyvd6FI7lmUlxn1w6QUAAO+4Ej4mTJigTZs26fjx46qsrNTbb7+txsZGjR8/vl3bYDCokpKSlJdXWicaI3wAAOAVV+f5KCoq0siRI3Xs2DGtXbtWc+bMcXN3abMHnUa47AIAgGccH3AqSWvXrpUxRhMnTtTevXt1xx13aNKkSVqwYIEbu+s1plgHAMB7rlQ+IpGIFi5cqEmTJun666/XjBkztHbtWuXl5bmxu14Lc7stAACec6Xycc011+iaa65xY9OOKm2pfESY5RQAAM/k7LNdpKTKRy2VDwAAvJLj4YMxHwAAeC2nw4d9twvPdwEAwDs5HT7sygdPtgUAwDs5HT6ofAAA4L2cDh+Jykddo4wxWe4NAAC5IafDh135aIob1USbstwbAAByQ06Hj4I8vwrymv8ETLEOAIA3cjp8SFK4kFlOAQDwEuGDuT4AAPBUzocP7ngBAMBbhI+i1jteAACA+3I+fIQY8wEAgKdyPnyUDqLyAQCAlwgfjPkAAMBTOR8+QtztAgCAp3I+fFD5AADAW4QPnmwLAICncj58hFsqH8dqqXwAAOAFwkdL5aO6vklNsXiWewMAwMBH+CjMS7yPcOkFAADX5Xz4CPh9Ki4ISGLcBwAAXsj58CG1XnrhjhcAANxH+FDr7bbHaql8AADgNsKHWu944bILAADuI3wo+fkuXHYBAMBthA+13vHCk20BAHAf4UNJE43xfBcAAFxH+FDrZZcI4QMAANcRPiSVFtmVDy67AADgNsKHpFBizAeVDwAA3OZ4+IjFYlqyZInGjRunwsJCTZgwQffdd5+MMU7vyjH2PB/c7QIAgPsCTm/wwQcf1PLly7V69WpNnjxZ27dv14IFCxQKhfTd737X6d05ojV8UPkAAMBtjoePt956S3PmzNGVV14pSRo7dqyeffZZvf32207vyjGhlgGnJxpjqm+MqSDPn+UeAQAwcDl+2eWCCy7Qhg0b9MEHH0iS/vd//1dvvPGGZs+e3WH7aDSq6urqlJfXSgoC8vssSVQ/AABwm+OVj7vuukvV1dWaNGmS/H6/YrGY7r//fs2bN6/D9hUVFbrnnnuc7kZaLMtSuDBPR2sbVHWiQSNCBVntDwAAA5njlY/nn39ev/jFL/TMM89ox44dWr16tX70ox9p9erVHbZfvHixIpFI4lVZWel0l3rEfrItD5cDAMBdjlc+7rjjDt1111269tprJUlTpkzR/v37VVFRofnz57drHwwGFQwGne5G2ppnOa3ljhcAAFzmeOWjrq5OPl/qZv1+v+LxuNO7cpQ9yylzfQAA4C7HKx9XXXWV7r//fo0ePVqTJ0/Wzp079eMf/1g33nij07tylP18l6oTVD4AAHCT4+Hjscce05IlS/Ttb39bR44cUVlZmb71rW/p7rvvdnpXjrKfbMvdLgAAuMvx8FFcXKxHHnlEjzzyiNObdlXi+S61VD4AAHATz3ZpYd/tUnWCygcAAG4ifLTg+S4AAHiD8NEizJNtAQDwBOGjRZjKBwAAniB8tCgtar3bxRiT5d4AADBwET5ahAubKx9NcaPj0aYs9wYAgIGL8NGiMN+vYKD5z8FcHwAAuIfwkaT1jhfCBwAAbiF8JEk82ZZBpwAAuIbwkYTwAQCA+wgfSbjsAgCA+wgfScKEDwAAXEf4SFLKZRcAAFxH+EiSeLgc4QMAANcQPpLYl114vgsAAO4hfCRJDDg9QfgAAMAthI8kXHYBAMB9hI8kiQGntYQPAADcQvhIYo/5qK5vUizOk20BAHAD4SNJuDAv8T7CuA8AAFxB+EgS8PtUHAxIYq4PAADcQvhoI1zEoFMAANxE+GiD57sAAOAuwkcboUJ7inXCBwAAbiB8tNFa+eCyCwAAbiB8tFGamGiMygcAAG4gfLTR+nwXKh8AALiB8NFGmMoHAACuIny0UUrlAwAAVxE+2qDyAQCAuwgfbYS52wUAAFc5Hj7Gjh0ry7LavRYuXOj0rlyReLItlQ8AAFwRcHqD27ZtUywWS3x+//33ddlll+nqq692eleusCsfJxpjqm+MqSDPn+UeAQAwsDgePoYOHZry+YEHHtCECRP0hS98welduaKkICC/z1IsbhQ50Uj4AADAYa6O+WhoaNDTTz+tG2+8UZZlddgmGo2quro65ZVNlmUlTbHOuA8AAJzmavh44YUXVFVVpRtuuKHTNhUVFQqFQolXeXm5m13qEfuOl2O1jPsAAMBproaPJ598UrNnz1ZZWVmnbRYvXqxIJJJ4VVZWutmlHrHn+oicoPIBAIDTHB/zYdu/f7/Wr1+vX//61122CwaDCgaDbnWjV7jjBQAA97hW+Vi5cqWGDRumK6+80q1duCZUyCynAAC4xZXwEY/HtXLlSs2fP1+BgGvFFdfwZFsAANzjSvhYv369Pv74Y914441ubN51pUXMcgoAgFtcKUvMmjVLxhg3Nu2J1lttqXwAAOA0nu3SgVKe7wIAgGsIHx1gzAcAAO4hfHTAfr4Ll10AAHAe4aMD4UTlo6Ffj10BAKAvInx0wB7z0RQ3Oh5tynJvAAAYWAgfHSjM9ysYaP7TMO4DAABnET46EWbQKQAAriB8dKJ0EFOsAwDgBsJHJxKVjxNUPgAAcBLhoxNMNAYAgDsIH52wKx/Haql8AADgJMJHJ8KM+QAAwBWEj07YU6xHGPMBAICjCB+dCBdS+QAAwA2Ej04kxnwwzwcAAI4ifHSitKi58hGh8gEAgKMIH50opfIBAIArCB+dCLWM+aiub1QszpNtAQBwCuGjE/aYD2O44wUAACcRPjqR5/epOBiQxCynAAA4ifDRhXAR4z4AAHAa4aML9lwfVD4AAHAO4aMLzPUBAIDzCB9d4Mm2AAA4j/DRBbvyUUXlAwAAxxA+usCTbQEAcB7howv2LKdVzPMBAIBjCB9dYMwHAADOI3x0IWTf7VJL5QMAAKcQPrpA5QMAAOcRPrrAmA8AAJznSvj485//rH/4h3/QkCFDVFhYqClTpmj79u1u7MpV9gyndQ0xRZtiWe4NAAADQ8DpDR47dkwXXnihvvjFL+qVV17R0KFDtWfPHpWWljq9K9cVFwTks6S4aZ7rY3iJP9tdAgCg33M8fDz44IMqLy/XypUrE8vGjRvn9G484fNZCg/K119rG1rCR0G2uwQAQL/n+GWX3/zmN/rsZz+rq6++WsOGDdPZZ5+tn/zkJ522j0ajqq6uTnn1Ja3Pd2HQKQAATnA8fHz00Udavny5Tj31VK1du1a33HKLvvvd72r16tUdtq+oqFAoFEq8ysvLne5SRsKF9hTrhA8AAJzgePiIx+M655xz9MMf/lBnn322br75Zn3zm9/UE0880WH7xYsXKxKJJF6VlZVOdykjpYkp1rnjBQAAJzgePkaOHKkzzjgjZdnpp5+ujz/+uMP2wWBQJSUlKa++JJyY64PwAQCAExwPHxdeeKF2796dsuyDDz7QmDFjnN6VJ1qfbMtlFwAAnOB4+Pinf/onbdmyRT/84Q+1d+9ePfPMM/qP//gPLVy40OldeaKUAacAADjK8fBx3nnnac2aNXr22Wd15pln6r777tMjjzyiefPmOb0rT3DZBQAAZzk+z4ckfelLX9KXvvQlNzbtuVLCBwAAjuLZLt1gng8AAJxF+OhGa/ig8gEAgBMIH92wL7tETjTIGJPl3gAA0P8RPrphh4/GmFFtA0+2BQAgU4SPbhTk+ZQfaP4zHatl3AcAAJkifHTDsqzEXB/c8QIAQOYIHz2QuN32BJUPAAAyRfjogVAhd7wAAOAUwkcPtE40RuUDAIBMET56oLSIMR8AADiF8NED9vNdmOUUAIDMET56IFxI5QMAAKcQPnqglMoHAACOIXz0QJh5PgAAcAzhowfC3O0CAIBjCB89UMqTbQEAcAzhowfsykd1faNicZ5sCwBAJggfPWCP+TBGqj5B9QMAgEwQPnogz+/TScGAJO54AQAgU4SPHgoz7gMAAEcQPnrInusjwpNtAQDICOGjhxKVj1oqHwAAZILw0UM83wUAAGcQPnrInusjwt0uAABkhPDRQ1Q+AABwBuGjh+wn23K3CwAAmSF89FBpkf1wOSofAABkgvDRQ60Pl6PyAQBAJggfPWRfdiF8AACQGcJHD5Uy4BQAAEcQPnrIDh91DTFFm2JZ7g0AAP2X4+Fj2bJlsiwr5TVp0iSnd+O54oKAfFbz+wiXXgAA6LWAGxudPHmy1q9f37qTgCu78ZTPZylUmKdjdY06VteoYSUF2e4SAAD9kiupIBAIaMSIEW5sOqtKB+W3hA/GfQAA0FuujPnYs2ePysrKNH78eM2bN08ff/xxp22j0aiqq6tTXn2V/XA57ngBAKD3HA8f06ZN06pVq/Tqq69q+fLl2rdvnz7/+c+rpqamw/YVFRUKhUKJV3l5udNdckxpYq4PKh8AAPSW4+Fj9uzZuvrqqzV16lRdfvnlevnll1VVVaXnn3++w/aLFy9WJBJJvCorK53ukmNCg5hiHQCATLk+EjQcDuu0007T3r17O1wfDAYVDAbd7oYjqHwAAJA51+f5OH78uD788EONHDnS7V25rpQxHwAAZMzx8HH77bdr06ZN+tOf/qS33npLX/nKV+T3+3Xdddc5vSvPhZjlFACAjDl+2eWTTz7Rddddp6NHj2ro0KGaMWOGtmzZoqFDhzq9K89R+QAAIHOOh4/nnnvO6U32GYkxHyeofAAA0Fs82yUNYe52AQAgY4SPNIST7nYxxmS5NwAA9E+EjzTYYz4aY0a1DTzZFgCA3iB8pKEwz6/8QPOfjLk+AADoHcJHGizLUriQO14AAMgE4SNNpcz1AQBARggfaeLJtgAAZIbwkSae7wIAQGYIH2lirg8AADJD+EhTmDEfAABkhPCRJnuujwiVDwAAeoXwkabWyy5UPgAA6A3CR5paL7tQ+QAAoDcIH2nibhcAADJD+EiTPeaj6gSVDwAAeoPwkaaQPeD0RKNicZ5sCwBAuggfaQoXNl92MUaqpvoBAEDaCB9pyg/4dFIwIIlLLwAA9Abhoxe43RYAgN4jfPRC68PlCB8AAKSL8NEL9u22x2q57AIAQLoIH71gTzTGmA8AANJH+OiFcCGXXQAA6C3CRy+UMuAUAIBeI3z0QuKyC893AQAgbYSPXigtsi+7ED4AAEgX4aMX7FlOuewCAED6CB+90DrPB5UPAADSRfjohdLEmA8qHwAApIvw0Qt25aO2IaaGpniWewMAQP9C+OiFkoI8+azm91Q/AABIj+vh44EHHpBlWVq0aJHbu/KMz2cpZE80xiynAACkxdXwsW3bNq1YsUJTp051czdZ0fp8FyofAACkw7Xwcfz4cc2bN08/+clPVFpa6tZusiaUmOWUygcAAOlwLXwsXLhQV155pWbOnNllu2g0qurq6pRXf8AdLwAA9E7AjY0+99xz2rFjh7Zt29Zt24qKCt1zzz1udMNVibk+GPMBAEBaHK98VFZW6nvf+55+8YtfqKCgoNv2ixcvViQSSbwqKyud7pIrmOUUAIDecbzy8c477+jIkSM655xzEstisZhef/11/fu//7ui0aj8fn9iXTAYVDAYdLobrrOfbFtVS+UDAIB0OB4+Lr30Ur333nspyxYsWKBJkybpzjvvTAke/Vm4iMoHAAC94Xj4KC4u1plnnpmyrKioSEOGDGm3vD8rZcwHAAC9wgynvWSP+eBuFwAA0uPK3S5tbdy40YvdeCrMPB8AAPQKlY9eKm0Z8xGpa5QxJsu9AQCg/yB89JI95qMhFlddQyzLvQEAoP8gfPRSYZ5f+f7mPx93vAAA0HOEj16yLKt1llPGfQAA0GOEjwy0Pt+F8AEAQE8RPjLQ+mRbLrsAANBThI8MJCYaI3wAANBjhI8McNkFAID0ET4yEB5kP9+F8AEAQE8RPjIQ5rILAABpI3xkoJQBpwAApI3wkQH7sgtPtgUAoOcIHxkIFzLJGAAA6SJ8ZMB+uByXXQAA6DnCRwbsAaeRE42Kx3myLQAAPUH4yEC4sLnyYYxUXc+lFwAAeoLwkYH8gE9F+X5JzPUBAEBPET4y1DrRGOM+AADoCcJHhkqLWsZ9UPkAAKBHCB8Zssd9UPkAAKBnCB8ZCidmOaXyAQBATxA+MtT6ZFsqHwAA9AThI0Olg5jlFACAdBA+MhTibhcAANJC+MgQlQ8AANJD+MhQYszHCSofAAD0BOEjQ4m7XWqpfAAA0BOEjwyFudsFAIC0ED4yZI/5qG2IqaEpnuXeAADQ9xE+MlRSkCfLan7PuA8AALpH+MiQz2cpVMgdLwAA9JTj4WP58uWaOnWqSkpKVFJSounTp+uVV15xejd9in3Hy7FaKh8AAHTH8fAxatQoPfDAA3rnnXe0fft2XXLJJZozZ4527drl9K76DPuOl6oTVD4AAOhOwOkNXnXVVSmf77//fi1fvlxbtmzR5MmTnd5dn8DzXQAA6DnHw0eyWCymX/3qV6qtrdX06dM7bBONRhWNRhOfq6ur3eySK8KFPNkWAICecmXA6XvvvaeTTjpJwWBQ//iP/6g1a9bojDPO6LBtRUWFQqFQ4lVeXu5Gl1wV5vkuAAD0mCvhY+LEiXr33Xe1detW3XLLLZo/f77+8Ic/dNh28eLFikQiiVdlZaUbXXKVPddHhMoHAADdcuWyS35+vk455RRJ0rnnnqtt27bp3/7t37RixYp2bYPBoILBoBvd8ExiinUqHwAAdMuTeT7i8XjKuI6BpvWyC5UPAAC643jlY/HixZo9e7ZGjx6tmpoaPfPMM9q4caPWrl3r9K76DPtuFy67AADQPcfDx5EjR3T99dfr4MGDCoVCmjp1qtauXavLLrvM6V31GVx2AQCg5xwPH08++aTTm+zzEpOM1TXKGCPLftgLAABoh2e7OMC+7NIQi6uuIZbl3gAA0LcRPhwwKN+vfH/zn5Ip1gEA6BrhwwGWZSlkj/vg4XIAAHSJ8OGQ0qRxHwAAoHOED4cwxToAAD1D+HBIovLBmA8AALpE+HBIuLC58lHFmA8AALpE+HBIuMieaIzKBwAAXXHlwXK5yJ7r4//9/oBi8bg+N36Ipo0fosFF+VnuGQAAfQvhwyGfHVOqfL9Pn9ZEtXrzfq3evF+SNGlEsT43foimTxiiaeMGJwamAgCQqyxjjMl2J5JVV1crFAopEomopKQk291Jy19rG7T1o6Pa8tFRbf7oqD44fDxlvWVJp48o0fQJQ/S58UN0/rjBChXmZam3AAA4J53/fhM+XPSX41Ft/eiv2vzRX7T5w6P68NPalPU+S5pcFtLnxg/W9AlDdN7YwSouIIwAAPofwkcfdaSmXls++qs2f3hUWz86qo/+0j6MTPlMSJ9rqYycN3awTgpyZQwA0PcRPvqJQ5F6bUm6TLP/aF3Ker/P0tRRoeYxI+OH6NwxpSoijAAA+iDCRz91oOpEcxD58Ki27Duqyr+eaNcm3+/ToKBfRfkBDcr3a1AwoKJ8vwblB1QUbPln8vKO1id9vygYUDDgk2VZWThiAMBAQfgYICr/WtdSGfmrtnx0VH+uah9GnOCz1BxGgn6dFAw0vwoCKspv/qe9rCgYUHGb5UXBQMp3BuX55fMRZAAg1xA+BiBjjKrrm1QbbVJdQ5NqozHVNjSpzv5nQ6xlXZvlHay3v3+iMeZ4P62WIFPUQZApzPcrGPApGPArP+BLvA/m+ZTv9ymY13Zd6ueCPJ/y/f6Wdq3r/IQdAMi6dP77zQCCfsKyLIUK8xy9NTcWNzrRGFNdtEm1LeHkeLRJx+ubVNvQpJqWsHO8i+W10Zhq6htV2xBTLG5kjBLtDyvqWF+7EvBZiRDis6zEP32W2iyTfD5Lfqtlvc+S36eWts1t/JYlq+V7fp8ly7Lkb/nc/N6Sz6fW9y3bTN5f8jqrzb4T7SwrZV1Ku5Z19nt7vc9KXt+yztfa3p/StnV98ne726+vq3W+zrdh98dScwC11Lws5b1a+85lPiC3ET5ymN9nJaoTmTLGqL4xnggetdH24aW+MaZoU1zRprgamuKKNrV8boyrIRZXNLE+1rI+3v5zY/PneFK9rilu1NTgfBUH7utpaLFa2igpfCUvt1pWti5v/317f/a6RHBKdCblHynrrMQ6S21zU4ftWvbR+r41pNnvfXYbS4n3dv98if5aLaEt9ViT37f+PayUdanf6TgAtluW0rYlbPqbg60d5AM+O7i3vLfXtXz2W63v7bDv90l+ny8R9gM+n3w+tW7X3k5LYPYnbaf1fxY6WO5LDcjJ69G3ET7gCMuyVJjvV2G+X0OLg67vrynWPpzE4kZxYxSLq+WfzZ/jRq3v40YxYxS327QsS2nT8l3Tsiy5TdwYmcS2lWhvf98k7d/Y2zdq+X6bdi2f227PJLbbuh27v3b75PXxpPWmTZ8S+0laHzOtf4vENuy/gb2/Nn+zjo7VCXZ/kpY4sl0gpTKn1iqiz7IDX2qlMDkQJj77Wj+3+15S2PO1CbVKtOk8aNrb7i4wJu/L7kPbwJjct7ahVGrtny9p20OLg1r4xVOydHYIH+inAn6fAn6fitzPOehEckgxag42xqj1fVIbJS2PG9OyrnmZjJqDUtL34i3hpu327ACllH2o4/130Be7vRJ9aT2W5qVK2W/ywtbvtq6zt91uG0ntWvuS2v94mz7GTfI2mwNjar9Tj9n+OyopaDbvI6kvbf7erftov3/Tpp3d33jcqCneGtxjcfvVvD6xzm6XFPybYq3hPXld4tXR/xC0aWf/O5bcticjFWNxo1jKWUWyCUOLCB8A+p/k8TCAl9pW51LCSVKYMWqtPEptq4fJga21fSJ8mdT2dihOCcptgpodsu3g2FHYbA2Dpk34TF2WHA7jLanQ7kPbMBk3rcG0dZ/t2ybvtzTLDz0lfAAA+hWCb//ny3YHAABAbiF8AAAATxE+AACApwgfAADAU4QPAADgKcIHAADwFOEDAAB4ivABAAA85Xj4qKio0Hnnnafi4mINGzZMc+fO1e7du53eDQAA6KccDx+bNm3SwoULtWXLFq1bt06NjY2aNWuWamtrnd4VAADohyxjP4HIJZ9++qmGDRumTZs26aKLLuq2fXV1tUKhkCKRiEpKStzsGgAAcEg6//12/dkukUhEkjR48OAO10ejUUWj0cTn6upqt7sEAACyyNUBp/F4XIsWLdKFF16oM888s8M2FRUVCoVCiVd5ebmbXQIAAFnm6mWXW265Ra+88oreeOMNjRo1qsM2bSsfkUhEo0ePVmVlJZddAADoJ6qrq1VeXq6qqiqFQqEu27p22eXWW2/VSy+9pNdff73T4CFJwWBQwWAw8dm+7EIFBACA/qempqbb8OF45cMYo+985ztas2aNNm7cqFNPPTWt78fjcR04cEDFxcWyLMvJriVSWS5UVXLpWKXcOl6OdeDKpePlWAceY4xqampUVlYmn6/rUR2OVz4WLlyoZ555Ri+++KKKi4t16NAhSVIoFFJhYWG33/f5fF1WSpxQUlIyoP8FSJZLxyrl1vFyrANXLh0vxzqwdFfxsDk+4HT58uWKRCK6+OKLNXLkyMTrl7/8pdO7AgAA/ZDjlQ+Xpw0BAAD9XE492yUYDGrp0qUpA1wHqlw6Vim3jpdjHbhy6Xg51tzm+gynAAAAyXKq8gEAALKP8AEAADxF+AAAAJ4ifAAAAE8RPgAAgKcGXPh4/PHHNXbsWBUUFGjatGl6++23u2z/q1/9SpMmTVJBQYGmTJmil19+2aOe9l5FRYXOO+88FRcXa9iwYZo7d652797d5XdWrVoly7JSXgUFBR71ODPLli1r1/dJkyZ1+Z3+eF4laezYse2O1bIsLVy4sMP2/em8vv7667rqqqtUVlYmy7L0wgsvpKw3xujuu+/WyJEjVVhYqJkzZ2rPnj3dbjfd37xXujrexsZG3XnnnZoyZYqKiopUVlam66+/XgcOHOhym735LXihu3N7ww03tOv3FVdc0e12++K57e5YO/r9Wpalhx9+uNNt9tXz6qYBFT5++ctf6vvf/76WLl2qHTt26KyzztLll1+uI0eOdNj+rbfe0nXXXadvfOMb2rlzp+bOnau5c+fq/fff97jn6dm0aZMWLlyoLVu2aN26dWpsbNSsWbNUW1vb5fdKSkp08ODBxGv//v0e9ThzkydPTun7G2+80Wnb/npeJWnbtm0px7lu3TpJ0tVXX93pd/rLea2trdVZZ52lxx9/vMP1Dz30kB599FE98cQT2rp1q4qKinT55Zervr6+022m+5v3UlfHW1dXpx07dmjJkiXasWOHfv3rX2v37t368pe/3O120/kteKW7cytJV1xxRUq/n3322S632VfPbXfHmnyMBw8e1FNPPSXLsvTVr361y+32xfPqKjOAnH/++WbhwoWJz7FYzJSVlZmKiooO219zzTXmyiuvTFk2bdo0861vfcvVfjrtyJEjRpLZtGlTp21WrlxpQqGQd51y0NKlS81ZZ53V4/YD5bwaY8z3vvc9M2HCBBOPxztc31/PqySzZs2axOd4PG5GjBhhHn744cSyqqoqEwwGzbPPPtvpdtL9zWdL2+PtyNtvv20kmf3793faJt3fQjZ0dKzz5883c+bMSWs7/eHc9uS8zpkzx1xyySVdtukP59VpA6by0dDQoHfeeUczZ85MLPP5fJo5c6Y2b97c4Xc2b96c0l6SLr/88k7b91WRSESSNHjw4C7bHT9+XGPGjFF5ebnmzJmjXbt2edE9R+zZs0dlZWUaP3685s2bp48//rjTtgPlvDY0NOjpp5/WjTfe2OUTnvvzebXt27dPhw4dSjlvoVBI06ZN6/S89eY335dFIhFZlqVwONxlu3R+C33Jxo0bNWzYME2cOFG33HKLjh492mnbgXJuDx8+rN/+9rf6xje+0W3b/npee2vAhI+//OUvisViGj58eMry4cOHJ56s29ahQ4fSat8XxeNxLVq0SBdeeKHOPPPMTttNnDhRTz31lF588UU9/fTTisfjuuCCC/TJJ5942NvemTZtmlatWqVXX31Vy5cv1759+/T5z39eNTU1HbYfCOdVkl544QVVVVXphhtu6LRNfz6vyexzk855681vvq+qr6/XnXfeqeuuu67Lp56m+1voK6644gr97Gc/04YNG/Tggw9q06ZNmj17tmKxWIftB8q5Xb16tYqLi/V3f/d3Xbbrr+c1E44/WA7eWrhwod5///1urw9Onz5d06dPT3y+4IILdPrpp2vFihW677773O5mRmbPnp14P3XqVE2bNk1jxozR888/36P/o+ivnnzySc2ePVtlZWWdtunP5xXNGhsbdc0118gYo+XLl3fZtr/+Fq699trE+ylTpmjq1KmaMGGCNm7cqEsvvTSLPXPXU089pXnz5nU7CLy/ntdMDJjKx8knnyy/36/Dhw+nLD98+LBGjBjR4XdGjBiRVvu+5tZbb9VLL72k1157TaNGjUrru3l5eTr77LO1d+9el3rnnnA4rNNOO63Tvvf38ypJ+/fv1/r163XTTTel9b3+el7tc5POeevNb76vsYPH/v37tW7dui6rHh3p7rfQV40fP14nn3xyp/0eCOf2f/7nf7R79+60f8NS/z2v6Rgw4SM/P1/nnnuuNmzYkFgWj8e1YcOGlP8zTDZ9+vSU9pK0bt26Ttv3FcYY3XrrrVqzZo3++7//W+PGjUt7G7FYTO+9955GjhzpQg/ddfz4cX344Yed9r2/ntdkK1eu1LBhw3TllVem9b3+el7HjRunESNGpJy36upqbd26tdPz1pvffF9iB489e/Zo/fr1GjJkSNrb6O630Fd98sknOnr0aKf97u/nVmquXJ577rk666yz0v5ufz2vacn2iFcnPffccyYYDJpVq1aZP/zhD+bmm2824XDYHDp0yBhjzNe//nVz1113Jdq/+eabJhAImB/96Efmj3/8o1m6dKnJy8sz7733XrYOoUduueUWEwqFzMaNG83BgwcTr7q6ukSbtsd6zz33mLVr15oPP/zQvPPOO+baa681BQUFZteuXdk4hLTcdtttZuPGjWbfvn3mzTffNDNnzjQnn3yyOXLkiDFm4JxXWywWM6NHjzZ33nlnu3X9+bzW1NSYnTt3mp07dxpJ5sc//rHZuXNn4u6OBx54wITDYfPiiy+a3//+92bOnDlm3Lhx5sSJE4ltXHLJJeaxxx5LfO7uN59NXR1vQ0OD+fKXv2xGjRpl3n333ZTfcTQaTWyj7fF291vIlq6Otaamxtx+++1m8+bNZt++fWb9+vXmnHPOMaeeeqqpr69PbKO/nNvu/j02xphIJGIGDRpkli9f3uE2+st5ddOACh/GGPPYY4+Z0aNHm/z8fHP++eebLVu2JNZ94QtfMPPnz09p//zzz5vTTjvN5Ofnm8mTJ5vf/va3Hvc4fZI6fK1cuTLRpu2xLlq0KPF3GT58uPnbv/1bs2PHDu873wtf+9rXzMiRI01+fr75zGc+Y772ta+ZvXv3JtYPlPNqW7t2rZFkdu/e3W5dfz6vr732Wof/3trHE4/HzZIlS8zw4cNNMBg0l156abu/wZgxY8zSpUtTlnX1m8+mro533759nf6OX3vttcQ22h5vd7+FbOnqWOvq6sysWbPM0KFDTV5enhkzZoz55je/2S5E9Jdz292/x8YYs2LFClNYWGiqqqo63EZ/Oa9usowxxtXSCgAAQJIBM+YDAAD0D4QPAADgKcIHAADwFOEDAAB4ivABAAA8RfgAAACeInwAAABPET4AAICnCB8AAMBThA8AAOApwgcAAPDU/wc3hu5X6wrDAgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plot the loss and accuracy\n",
    "plt.plot(losses)\n",
    "plt.title(\"Loss\")\n",
    "plt.show()\n",
    "\n",
    "plt.plot(accuracy)\n",
    "plt.title(\"Accuracy\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.6081730769230769\n"
     ]
    }
   ],
   "source": [
    "# test_accuracies = []\n",
    "# all_prediction_logits = []\n",
    "# for batch, (X,y) in tqdm(enumerate((test_loader))):\n",
    "#     optimizer.zero_grad()\n",
    "#     X, y = X,y\n",
    "#     X,y= X.cuda().float(), y.cuda().long()\n",
    "\n",
    "\n",
    "#     prediction_logits, auxiliary,tau = model(X)\n",
    "\n",
    "#     aux_loss = auxiliary_criterion(auxiliary, X)\n",
    "#     loss = aux_loss\n",
    "#     # print(\"aux_loss\", aux_loss.item())\n",
    "#     loss.backward()\n",
    "#     optimizer.step()\n",
    "    \n",
    "#     prediction_logits, auxiliary,tau = model(X)\n",
    "#     prediction = F.softmax(prediction_logits, dim=1)\n",
    "#     prediction = torch.argmax(prediction, dim=1)\n",
    "#     all_prediction_logits.extend(prediction)\n",
    "#     batch_accuracy = (prediction == y).sum().item() / len(y)\n",
    "#     test_accuracies.append(batch_accuracy)\n",
    "\n",
    "# print(f\"Test Accuracy: {np.mean(test_accuracies)}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 1.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " 0.0,\n",
       " ...]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Dataset (All datasets combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_live_test_02-Apr-2024_84.csv\n",
      "df_live_test_02-Apr-2024_85.csv\n",
      "df_live_test_02-Apr-2024_86.csv\n",
      "df_live_test_02-Apr-2024_92.csv\n",
      "df_live_test_02-Apr-2024_93.csv\n",
      "df_live_test_02-Apr-2024_94.csv\n",
      "df_live_test_02-Apr-2024_95.csv\n",
      "df_live_test_02-Apr-2024_96.csv\n",
      "df_live_test_02-Apr-2024_97.csv\n",
      "df_live_test_02-Apr-2024_98.csv\n",
      "df_live_test_02-Apr-2024_99.csv\n",
      "df_live_test_02-Apr-2024_102.csv\n",
      "df_live_test_02-Apr-2024_103.csv\n",
      "df_live_test_02-Apr-2024_104.csv\n",
      "df_live_test_02-Apr-2024_105.csv\n",
      "df_live_test_02-Apr-2024_106.csv\n",
      "df_live_test_02-Apr-2024_107.csv\n",
      "df_live_test_02-Apr-2024_108.csv\n",
      "df_live_test_02-Apr-2024_109.csv\n",
      "df_live_test_02-Apr-2024_110.csv\n",
      "df_live_test_02-Apr-2024_111.csv\n",
      "df_live_test_02-Apr-2024_112.csv\n",
      "df_live_test_02-Apr-2024_113.csv\n",
      "df_live_test_02-Apr-2024_117.csv\n",
      "df_live_test_02-Apr-2024_120.csv\n",
      "df_live_test_02-Apr-2024_121.csv\n",
      "df_live_test_02-Apr-2024_122.csv\n",
      "df_live_test_02-Apr-2024_123.csv\n",
      "df_live_test_02-Apr-2024_124.csv\n",
      "df_live_test_02-Apr-2024_125.csv\n",
      "df_live_test_02-Apr-2024_126.csv\n",
      "df_live_test_02-Apr-2024_127.csv\n",
      "df_live_test_02-Apr-2024_128.csv\n",
      "df_live_test_02-Apr-2024_129.csv\n",
      "df_live_test_02-Apr-2024_130.csv\n",
      "df_live_test_02-Apr-2024_131.csv\n",
      "df_live_test_02-Apr-2024_132.csv\n",
      "df_live_test_02-Apr-2024_133.csv\n",
      "df_live_test_02-Apr-2024_134.csv\n",
      "df_live_test_02-Apr-2024_135.csv\n",
      "df_live_test_02-Apr-2024_136.csv\n",
      "df_live_test_02-Apr-2024_137.csv\n",
      "df_live_test_02-Apr-2024_138.csv\n",
      "df_live_test_02-Apr-2024_139.csv\n",
      "df_live_test_02-Apr-2024_140.csv\n",
      "df_live_test_02-Apr-2024_141.csv\n",
      "df_live_test_02-Apr-2024_142.csv\n",
      "df_live_test_02-Apr-2024_143.csv\n",
      "df_live_test_02-Apr-2024_144.csv\n",
      "df_live_train_02-Apr-2024_84.csv\n",
      "df_live_train_02-Apr-2024_85.csv\n",
      "df_live_train_02-Apr-2024_86.csv\n",
      "df_live_train_02-Apr-2024_92.csv\n",
      "df_live_train_02-Apr-2024_93.csv\n",
      "df_live_train_02-Apr-2024_94.csv\n",
      "df_live_train_02-Apr-2024_95.csv\n",
      "df_live_train_02-Apr-2024_96.csv\n",
      "df_live_train_02-Apr-2024_97.csv\n",
      "df_live_train_02-Apr-2024_98.csv\n",
      "df_live_train_02-Apr-2024_99.csv\n",
      "df_live_train_02-Apr-2024_102.csv\n",
      "df_live_train_02-Apr-2024_103.csv\n",
      "df_live_train_02-Apr-2024_104.csv\n",
      "df_live_train_02-Apr-2024_105.csv\n",
      "df_live_train_02-Apr-2024_106.csv\n",
      "df_live_train_02-Apr-2024_107.csv\n",
      "df_live_train_02-Apr-2024_108.csv\n",
      "df_live_train_02-Apr-2024_109.csv\n",
      "df_live_train_02-Apr-2024_110.csv\n",
      "df_live_train_02-Apr-2024_111.csv\n",
      "df_live_train_02-Apr-2024_112.csv\n",
      "df_live_train_02-Apr-2024_113.csv\n",
      "df_live_train_02-Apr-2024_117.csv\n",
      "df_live_train_02-Apr-2024_120.csv\n",
      "df_live_train_02-Apr-2024_121.csv\n",
      "df_live_train_02-Apr-2024_122.csv\n",
      "df_live_train_02-Apr-2024_123.csv\n",
      "df_live_train_02-Apr-2024_124.csv\n",
      "df_live_train_02-Apr-2024_125.csv\n",
      "df_live_train_02-Apr-2024_126.csv\n",
      "df_live_train_02-Apr-2024_127.csv\n",
      "df_live_train_02-Apr-2024_128.csv\n",
      "df_live_train_02-Apr-2024_129.csv\n",
      "df_live_train_02-Apr-2024_130.csv\n",
      "df_live_train_02-Apr-2024_131.csv\n",
      "df_live_train_02-Apr-2024_132.csv\n",
      "df_live_train_02-Apr-2024_133.csv\n",
      "df_live_train_02-Apr-2024_134.csv\n",
      "df_live_train_02-Apr-2024_135.csv\n",
      "df_live_train_02-Apr-2024_136.csv\n",
      "df_live_train_02-Apr-2024_137.csv\n",
      "df_live_train_02-Apr-2024_138.csv\n",
      "df_live_train_02-Apr-2024_139.csv\n",
      "df_live_train_02-Apr-2024_140.csv\n",
      "df_live_train_02-Apr-2024_141.csv\n",
      "df_live_train_02-Apr-2024_142.csv\n",
      "df_live_train_02-Apr-2024_143.csv\n",
      "df_live_train_02-Apr-2024_144.csv\n"
     ]
    }
   ],
   "source": [
    "folder_path = 'live_data/live_data_02-Apr-2024'\n",
    "''' \n",
    "the folder path has 2 types of files - df_live_test and df_live_train\n",
    "Concatenate the files and save it as a single file\n",
    "'''\n",
    "# sort the files in increasing order of file name length\n",
    "def sort_files(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    files.sort(key=len)\n",
    "    return files\n",
    "\n",
    "def concat_files(folder_path):\n",
    "    df_test_list = pd.DataFrame()\n",
    "    df_train = pd.DataFrame()\n",
    "\n",
    "    files = sort_files(folder_path)\n",
    "    for file in files:\n",
    "        print(file)\n",
    "        if file[0:12] == 'df_live_test':\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            df_temp = pd.read_csv(file_path)\n",
    "            df_test_list = pd.concat([df_test_list, df_temp], axis=0)\n",
    "        elif file[0:13] == 'df_live_train':\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            df_temp = pd.read_csv(file_path)\n",
    "            df_train = pd.concat([df_train, df_temp], axis=0)\n",
    "    return df_test_list, df_train\n",
    "\n",
    "df_test,df=concat_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Open_n_val', 'High_n_val', 'Low_n_val', 'Close_n_val', 'Volume_n_val',\n",
       "       'SMA_10_val', 'SMA_20_val', 'CMO_14_val', 'High_n-Low_n_val',\n",
       "       'Open_n-Close_n_val', 'SMA_20-SMA_10_val', 'Close_n_slope_3_val',\n",
       "       'Close_n_slope_5_val', 'Close_n_slope_10_val', 'Open_n_changelen_val',\n",
       "       'High_n_changelen_val', 'Low_n_changelen_val', 'Close_n_changelen_val',\n",
       "       'High_n-Low_n_changelen_val', 'Open_n-Close_n_changelen_val',\n",
       "       'SMA_20-SMA_10_changelen_val', 'Close_n_slope_3_changelen_val',\n",
       "       'Close_n_slope_5_changelen_val', 'Close_n_slope_10_changelen_val',\n",
       "       'row_num', 'era', 'id', 'target_5_val', 'target_10_val', 'target_5',\n",
       "       'target_10'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode(value, encoding):\n",
    "    for key, val in encoding.items():\n",
    "        if value == key:\n",
    "            return val\n",
    "\n",
    "class_values_era = list(df.era.unique())\n",
    "class_values_era.sort()\n",
    "class_values_target = list(df.target_10_val.unique())\n",
    "class_values_target.sort()\n",
    "era_encoding = {val: i for i, val in enumerate(class_values_era)}\n",
    "target_encoding = {val: i for i, val in enumerate(class_values_target)}\n",
    "df[\"era\"] = df[\"era\"].apply(encode, args=(era_encoding,))\n",
    "df[\"target_5_val\"] = df[\"target_5_val\"].apply(encode, args=(target_encoding,))\n",
    "df[\"target_10_val\"] = df[\"target_10_val\"].apply(encode, args=(target_encoding,))\n",
    "\n",
    "\n",
    "dataset = df\n",
    "target_column = \"target_10_val\"\n",
    "output_classes = 5\n",
    "shuffle = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open_n_val</th>\n",
       "      <th>High_n_val</th>\n",
       "      <th>Low_n_val</th>\n",
       "      <th>Close_n_val</th>\n",
       "      <th>Volume_n_val</th>\n",
       "      <th>SMA_10_val</th>\n",
       "      <th>SMA_20_val</th>\n",
       "      <th>CMO_14_val</th>\n",
       "      <th>High_n-Low_n_val</th>\n",
       "      <th>Open_n-Close_n_val</th>\n",
       "      <th>...</th>\n",
       "      <th>Close_n_changelen_val</th>\n",
       "      <th>High_n-Low_n_changelen_val</th>\n",
       "      <th>Open_n-Close_n_changelen_val</th>\n",
       "      <th>SMA_20-SMA_10_changelen_val</th>\n",
       "      <th>Close_n_slope_3_changelen_val</th>\n",
       "      <th>Close_n_slope_5_changelen_val</th>\n",
       "      <th>Close_n_slope_10_changelen_val</th>\n",
       "      <th>row_num</th>\n",
       "      <th>target_10_val</th>\n",
       "      <th>era</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.5</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>139</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>140</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.75</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>141</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.75</td>\n",
       "      <td>142</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.75</td>\n",
       "      <td>...</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>143</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12862 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Open_n_val  High_n_val  Low_n_val  Close_n_val  Volume_n_val  SMA_10_val  \\\n",
       "0           0.0        1.00       0.00         1.00          0.00         1.0   \n",
       "1           1.0        1.00       0.75         1.00          1.00         1.0   \n",
       "2           1.0        1.00       0.50         0.75          1.00         1.0   \n",
       "3           0.5        0.50       0.50         0.50          1.00         1.0   \n",
       "4           0.5        0.50       0.50         0.75          1.00         1.0   \n",
       "..          ...         ...        ...          ...           ...         ...   \n",
       "284         0.0        0.25       0.00         0.00          0.75         0.0   \n",
       "285         0.0        0.00       0.00         0.00          0.25         0.0   \n",
       "286         0.0        0.00       0.00         0.00          0.50         0.0   \n",
       "287         0.0        0.00       0.00         0.25          0.50         0.0   \n",
       "288         0.0        0.00       0.00         0.00          0.25         0.0   \n",
       "\n",
       "     SMA_20_val  CMO_14_val  High_n-Low_n_val  Open_n-Close_n_val  ...  \\\n",
       "0          0.75        0.50              1.00                0.00  ...   \n",
       "1          0.75        0.50              0.50                0.50  ...   \n",
       "2          0.75        0.50              1.00                0.75  ...   \n",
       "3          0.75        0.50              1.00                0.75  ...   \n",
       "4          0.75        0.50              0.75                0.00  ...   \n",
       "..          ...         ...               ...                 ...  ...   \n",
       "284        0.00        0.00              0.75                0.50  ...   \n",
       "285        0.00        0.00              0.00                0.50  ...   \n",
       "286        0.00        0.00              0.50                0.50  ...   \n",
       "287        0.00        0.25              0.50                0.25  ...   \n",
       "288        0.00        0.00              0.00                0.75  ...   \n",
       "\n",
       "     Close_n_changelen_val  High_n-Low_n_changelen_val  \\\n",
       "0                     0.50                        0.75   \n",
       "1                     0.75                        0.75   \n",
       "2                     0.25                        1.00   \n",
       "3                     0.00                        0.75   \n",
       "4                     0.75                        0.50   \n",
       "..                     ...                         ...   \n",
       "284                   0.50                        0.75   \n",
       "285                   0.25                        0.50   \n",
       "286                   0.75                        0.75   \n",
       "287                   1.00                        0.50   \n",
       "288                   0.50                        0.25   \n",
       "\n",
       "     Open_n-Close_n_changelen_val  SMA_20-SMA_10_changelen_val  \\\n",
       "0                            0.25                         0.50   \n",
       "1                            0.50                         0.50   \n",
       "2                            0.75                         0.75   \n",
       "3                            0.25                         0.75   \n",
       "4                            0.00                         0.75   \n",
       "..                            ...                          ...   \n",
       "284                          0.75                         0.50   \n",
       "285                          0.75                         0.25   \n",
       "286                          0.25                         0.25   \n",
       "287                          0.00                         0.25   \n",
       "288                          0.50                         0.25   \n",
       "\n",
       "     Close_n_slope_3_changelen_val  Close_n_slope_5_changelen_val  \\\n",
       "0                             0.50                           0.50   \n",
       "1                             1.00                           0.75   \n",
       "2                             0.25                           0.25   \n",
       "3                             0.25                           0.00   \n",
       "4                             1.00                           0.75   \n",
       "..                             ...                            ...   \n",
       "284                           1.00                           0.75   \n",
       "285                           0.50                           1.00   \n",
       "286                           0.75                           1.00   \n",
       "287                           1.00                           0.50   \n",
       "288                           0.50                           0.25   \n",
       "\n",
       "     Close_n_slope_10_changelen_val  row_num  target_10_val  era  \n",
       "0                              0.50        0              0    0  \n",
       "1                              0.75        1              0    0  \n",
       "2                              0.25        2              0    0  \n",
       "3                              0.25        3              1    0  \n",
       "4                              0.75        4              0    0  \n",
       "..                              ...      ...            ...  ...  \n",
       "284                            0.75      139              2    0  \n",
       "285                            0.75      140              2    0  \n",
       "286                            0.75      141              2    0  \n",
       "287                            0.75      142              2    0  \n",
       "288                            0.25      143              2    0  \n",
       "\n",
       "[12862 rows x 27 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_dataset = dataset.drop(columns=[\"target_5_val\", \"target_5\",\"target_10\",\"id\"])\n",
    "era = new_dataset.pop(\"era\")\n",
    "target = new_dataset.pop(target_column)\n",
    "new_dataset[target_column] = target\n",
    "new_dataset[\"era\"] = era\n",
    "new_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(new_dataset.drop(columns=[target_column,'era','row_num']).values, new_dataset[target_column].values)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=shuffle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'Open_n_val', 'High_n_val', 'Low_n_val', 'Close_n_val',\n",
       "       'Volume_n_val', 'SMA_10_val', 'SMA_20_val', 'CMO_14_val',\n",
       "       'High_n-Low_n_val', 'Open_n-Close_n_val', 'SMA_20-SMA_10_val',\n",
       "       'Close_n_slope_3_val', 'Close_n_slope_5_val', 'Close_n_slope_10_val',\n",
       "       'Open_n_changelen_val', 'High_n_changelen_val', 'Low_n_changelen_val',\n",
       "       'Close_n_changelen_val', 'High_n-Low_n_changelen_val',\n",
       "       'Open_n-Close_n_changelen_val', 'SMA_20-SMA_10_changelen_val',\n",
       "       'Close_n_slope_3_changelen_val', 'Close_n_slope_5_changelen_val',\n",
       "       'Close_n_slope_10_changelen_val', 'row_num'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_set = df_test\n",
    "target_column = \"row_num\"\n",
    "output_classes = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = CustomDataset(test_set.drop(columns=[target_column,'row_num','id']).values, new_test_dataset[target_column].values)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f1fc131a82724274b4840b92890d05c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test the model on test data\n",
    "test_accuracies = []\n",
    "predictions=[]\n",
    "all_prediction_logits = []\n",
    "\n",
    "for batch, (X,y) in tqdm(enumerate((test_loader))):\n",
    "    optimizer.zero_grad()\n",
    "    X, y = X,y\n",
    "    X,y= X.cuda().float(), y.cuda().long()\n",
    "    prediction_logits, auxiliary,tau = model(X)\n",
    "\n",
    "    aux_loss = auxiliary_criterion(auxiliary, X)\n",
    "    loss = aux_loss\n",
    "    # print(\"aux_loss\", aux_loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    prediction_logits, auxiliary,tau = model(X)\n",
    "    prediction = F.softmax(prediction_logits, dim=1)\n",
    "    prediction = torch.argmax(prediction, dim=1)\n",
    "    all_prediction_logits.extend(prediction)\n",
    "    # batch_accuracy = (prediction == y).sum().item() / len(y)\n",
    "    # test_accuracies.append(batch_accuracy)\n",
    "    predictions.append(prediction.item())\n",
    "\n",
    "    if batch == 10:\n",
    "        break\n",
    "# print(f\"Test Accuracy: {np.mean(test_accuracies)}\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Data (Pair of datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'live_data/live_data_08-Apr-2024'\n",
    "'''\n",
    "the folder path has 2 types of files - df_live_test and df_live_train\n",
    "Concatentae the files and save it as a single file\n",
    "'''\n",
    "# sort the files in increasing order of file name length\n",
    "def sort_files(folder_path):\n",
    "    files = os.listdir(folder_path)\n",
    "    files.sort(key=len)\n",
    "    return files\n",
    "\n",
    "\n",
    "def concat_files(folder_path):\n",
    "    df_test_list = []\n",
    "    df_train_list = []\n",
    "\n",
    "    df_test_list_names = []\n",
    "    df_train_list_names = []\n",
    "\n",
    "    files = sort_files(folder_path)\n",
    "    for file in files:\n",
    "        # print(file)\n",
    "        if file[0:12] == 'df_live_test':\n",
    "            df_test_list_names.append(file)\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            df_temp = pd.read_csv(file_path)\n",
    "            df_test_list.append(df_temp)\n",
    "        elif file[0:13] == 'df_live_train':\n",
    "            df_train_list_names.append(file)\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            df_temp = pd.read_csv(file_path)\n",
    "            df_train_list.append(df_temp)\n",
    "    # print(df_test_list_names)\n",
    "    # print(df_train_list_names)\n",
    "    # print(len(df_test_list), len(df_train_list))\n",
    "    return df_test_list, df_train_list\n",
    "\n",
    "df_test,df_train=concat_files(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fec92cb625649ce8088b59e26958baf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 35.764253241749415 Accuracy: 0.12094907407407407\n",
      "Epoch 1 Loss: 35.70821104286548 Accuracy: 0.11805555555555555\n",
      "Epoch 2 Loss: 35.65977958229175 Accuracy: 0.12094907407407407\n",
      "Epoch 3 Loss: 35.60600545657549 Accuracy: 0.11805555555555555\n",
      "Epoch 4 Loss: 35.55060009906273 Accuracy: 0.11226851851851852\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66432b4b7471444ebd3568a749f2457e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d745e3d63814b4d8737b7e38978b561",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 35.47948017307574 Accuracy: 0.11607142857142858\n",
      "Epoch 1 Loss: 35.43066369527094 Accuracy: 0.11830357142857142\n",
      "Epoch 2 Loss: 35.38011622509997 Accuracy: 0.11607142857142858\n",
      "Epoch 3 Loss: 35.32907584387395 Accuracy: 0.11160714285714285\n",
      "Epoch 4 Loss: 35.27713735464905 Accuracy: 0.1517857142857143\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc438fa404354882992437a7e63e50d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0f3cff98282c41d9b730e2253e3df5b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 35.0896122543593 Accuracy: 0.26264880952380953\n",
      "Epoch 1 Loss: 34.72175777495099 Accuracy: 0.26339285714285715\n",
      "Epoch 2 Loss: 34.335400610441866 Accuracy: 0.25669642857142855\n",
      "Epoch 3 Loss: 34.01627924257106 Accuracy: 0.25669642857142855\n",
      "Epoch 4 Loss: 33.75769986172036 Accuracy: 0.25669642857142855\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a67b1d6ad771490b8c0261b46afe444f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297cbef5e6e644ef807a79fd6c0c15c0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 33.45190085536195 Accuracy: 0.2688078703703704\n",
      "Epoch 1 Loss: 33.12829309188399 Accuracy: 0.26070601851851855\n",
      "Epoch 2 Loss: 32.69847299524091 Accuracy: 0.26273148148148145\n",
      "Epoch 3 Loss: 31.991748722152167 Accuracy: 0.2566550925925926\n",
      "Epoch 4 Loss: 30.907767638972814 Accuracy: 0.26273148148148145\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcf153ec0ee94106b8b25b1344d216e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcb322f6a4014666ba1dd689ebd6039a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 29.604419278513028 Accuracy: 0.25375000000000003\n",
      "Epoch 1 Loss: 28.844803127011517 Accuracy: 0.22625\n",
      "Epoch 2 Loss: 27.903707599839414 Accuracy: 0.26749999999999996\n",
      "Epoch 3 Loss: 26.87454387345531 Accuracy: 0.25375000000000003\n",
      "Epoch 4 Loss: 25.672541045092476 Accuracy: 0.22625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab38443e29eb44b5b773132362d7a40c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "911f2d68b5654e85ab8ec1ee09f49cd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 24.13701955868338 Accuracy: 0.17708333333333334\n",
      "Epoch 1 Loss: 23.391030761661316 Accuracy: 0.19791666666666666\n",
      "Epoch 2 Loss: 22.50349423331693 Accuracy: 0.19791666666666666\n",
      "Epoch 3 Loss: 21.347735720694388 Accuracy: 0.17708333333333334\n",
      "Epoch 4 Loss: 20.34662809147495 Accuracy: 0.1875\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf23ebabfdc462cb20dca39d17ef4f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "188f42737cc94f7992082c7554fe245c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 19.617723899510324 Accuracy: 0.286764705882353\n",
      "Epoch 1 Loss: 18.406398536223715 Accuracy: 0.3235294117647059\n",
      "Epoch 2 Loss: 17.25671787090163 Accuracy: 0.2959558823529412\n",
      "Epoch 3 Loss: 16.11025575517435 Accuracy: 0.2959558823529412\n",
      "Epoch 4 Loss: 14.975208148226947 Accuracy: 0.2959558823529412\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64739ec3dc3c4bfca3f31f8ec071cd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b3f8bb86e014369a183a76483387d6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 14.068415345571294 Accuracy: 0.29050925925925924\n",
      "Epoch 1 Loss: 13.059160490250996 Accuracy: 0.2986111111111111\n",
      "Epoch 2 Loss: 11.922466206799902 Accuracy: 0.30671296296296297\n",
      "Epoch 3 Loss: 11.032257978751403 Accuracy: 0.2824074074074074\n",
      "Epoch 4 Loss: 10.115343486129953 Accuracy: 0.2986111111111111\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c6b0792802941ff9eb97a9a4d072141",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f14d953fa8a14e87bb226dc5ab540110",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 8.682206915857726 Accuracy: 0.2638888888888889\n",
      "Epoch 1 Loss: 7.438551960074555 Accuracy: 0.21875\n",
      "Epoch 2 Loss: 6.341340205534899 Accuracy: 0.2638888888888889\n",
      "Epoch 3 Loss: 5.664206783690271 Accuracy: 0.2638888888888889\n",
      "Epoch 4 Loss: 5.171914742303243 Accuracy: 0.24131944444444445\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bd1876843a94e2791e81cfaff3f437c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "897569a7e1f546d980132cd4445e55bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 4.673316918810396 Accuracy: 0.314484126984127\n",
      "Epoch 1 Loss: 4.587382615928167 Accuracy: 0.3199404761904762\n",
      "Epoch 2 Loss: 4.36362158285819 Accuracy: 0.314484126984127\n",
      "Epoch 3 Loss: 4.372428246668842 Accuracy: 0.2926587301587302\n",
      "Epoch 4 Loss: 4.221236049435943 Accuracy: 0.3253968253968254\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b88febdc36407d8b32eb540d357340",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_predictions=[]\n",
    "model = TTA(input_size=24, classification_output_size=5, auxiliary_output_size=24)\n",
    "model.cuda() \n",
    "# classification_criterion = nn.CrossEntropyLoss()\n",
    "classification_criterion = NoiseAttentionLoss()\n",
    "auxiliary_criterion = nn.MSELoss() \n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "bagging_percent = 0.9\n",
    "\n",
    "\n",
    "for dataset_num in range(len(df_train)):\n",
    "    print(\"dataset_num\", dataset_num)\n",
    "    df = df_train[dataset_num]\n",
    "\n",
    "    class_values_era = list(df.era.unique())\n",
    "    class_values_era.sort()\n",
    "    class_values_target = list(df.target_10_val.unique())\n",
    "    class_values_target.sort()\n",
    "    era_encoding = {val: i for i, val in enumerate(class_values_era)}\n",
    "    target_encoding = {val: i for i, val in enumerate(class_values_target)}\n",
    "    df[\"era\"] = df[\"era\"].apply(encode, args=(era_encoding,))\n",
    "    df[\"target_5_val\"] = df[\"target_5_val\"].apply(encode, args=(target_encoding,))\n",
    "    df[\"target_10_val\"] = df[\"target_10_val\"].apply(encode, args=(target_encoding,))\n",
    "\n",
    "    dataset = df\n",
    "    target_column = \"target_10_val\"\n",
    "    output_classes = 5\n",
    "    shuffle = True\n",
    "\n",
    "    new_dataset = dataset.drop(columns=[\"target_5_val\", \"target_5\",\"target_10\",\"id\"])\n",
    "    era = new_dataset.pop(\"era\")\n",
    "    target = new_dataset.pop(target_column)\n",
    "    new_dataset[target_column] = target\n",
    "    new_dataset[\"era\"] = era\n",
    "\n",
    "    train_dataset = CustomDataset(new_dataset.drop(columns=[target_column,'era','row_num']).values, new_dataset[target_column].values)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=shuffle)\n",
    "\n",
    "    epochs = 5\n",
    "    losses = []\n",
    "    predictions = []\n",
    "    accuracy = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # loop = tqdm(train_loader, leave=True)\n",
    "        epoch_acc=[]\n",
    "        epoch_loss=[]\n",
    "        for batch,(X, y) in enumerate(train_loader):\n",
    "            X, y = X.cuda().float(), y.cuda().long()\n",
    "            \n",
    "            # # mask 5 columns in X\n",
    "            # mask = torch.randint(0, 27, (5,))\n",
    "            # X[:, mask] = 0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            prediction_logits, auxiliary,tau = model(X)\n",
    "            # print(tau)\n",
    "            prediction_softmax = F.softmax(prediction_logits, dim=1).to(torch.float64)\n",
    "            prediction = torch.argmax(prediction_softmax, dim=1)\n",
    "\n",
    "            loss1 = classification_criterion(prediction_softmax, y,tau)\n",
    "            # print(prediction_logits)\n",
    "            loss2 = auxiliary_criterion(auxiliary, X)\n",
    "            # print(loss1.item(), loss2.item()    )\n",
    "            accuracy_batch = (prediction == y).sum().item() / len(y)\n",
    "            epoch_acc.append(accuracy_batch)\n",
    "\n",
    "            loss = loss1 + loss2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # losses.append(loss.item())\n",
    "            epoch_loss.append(loss.item())\n",
    "            predictions.append(prediction)\n",
    "            # break\n",
    "            # if batch == bagging_percent * len(train_loader):\n",
    "            #     break\n",
    "        accuracy.append(np.mean(epoch_acc))\n",
    "        losses.append(np.mean(epoch_loss))\n",
    "        print(f\"Epoch {epoch} Loss: {np.mean(epoch_loss)} Accuracy: {np.mean(epoch_acc)}\")\n",
    "\n",
    "\n",
    "    df_test_list = df_test[dataset_num]\n",
    "    target_column = \"row_num\"\n",
    "    output_classes = 5\n",
    "\n",
    "    test_dataset = CustomDataset(df_test_list.drop(columns=[target_column,'row_num','id']).values, df_test_list[target_column].values)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # test the model on test data\n",
    "    test_accuracies = []\n",
    "    predictions=[]\n",
    "    all_prediction_logits = []\n",
    "\n",
    "    for batch, (X,y) in tqdm(enumerate((test_loader))):\n",
    "        optimizer.zero_grad()\n",
    "        X, y = X,y\n",
    "        X,y= X.cuda().float(), y.cuda().long()\n",
    "        prediction_logits, auxiliary,tau = model(X)\n",
    "\n",
    "        aux_loss = auxiliary_criterion(auxiliary, X)\n",
    "        loss = aux_loss\n",
    "        # print(\"aux_loss\", aux_loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        prediction_logits, auxiliary,tau = model(X)\n",
    "        prediction = F.softmax(prediction_logits, dim=1)\n",
    "        prediction = torch.argmax(prediction, dim=1)\n",
    "        all_prediction_logits.extend(prediction)\n",
    "        # batch_accuracy = (prediction == y).sum().item() / len(y)\n",
    "        # test_accuracies.append(batch_accuracy)\n",
    "        predictions.append(prediction.item())\n",
    "\n",
    "        if batch == 10:\n",
    "            break\n",
    "    all_predictions.append(predictions)\n",
    "    # print(f\"Test Accuracy: {np.mean(test_accuracies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0],\n",
       " [0],\n",
       " [3, 3, 3, 3, 3],\n",
       " [3, 3, 3, 3, 3],\n",
       " [3, 3],\n",
       " [3],\n",
       " [3],\n",
       " [3],\n",
       " [3, 3],\n",
       " [3]]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions to a file\n",
    "import csv\n",
    "with open('8Apr_predictions.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = 'live_data/live_data_05-Apr-2024'\n",
    "\n",
    "df_test,df_train=concat_files(folder_path)\n",
    "\n",
    "all_predictions=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "598e0da36e7e42cab5c913c1033d4b0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.214929055864428 Accuracy: 0.31120770676691734\n",
      "Epoch 1 Loss: 2.2182095327552713 Accuracy: 0.30157424812030076\n",
      "Epoch 2 Loss: 2.204700593422939 Accuracy: 0.3202537593984962\n",
      "Epoch 3 Loss: 2.2102154403569343 Accuracy: 0.32835996240601506\n",
      "Epoch 4 Loss: 2.2018471969545264 Accuracy: 0.3223684210526316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a218090783b46a583d2a8d460bad4d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb312e7c37224e4dab184c167d40d78b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.203497348638036 Accuracy: 0.32835996240601506\n",
      "Epoch 1 Loss: 2.185645286747602 Accuracy: 0.31649436090225563\n",
      "Epoch 2 Loss: 2.1929362937532333 Accuracy: 0.3105028195488722\n",
      "Epoch 3 Loss: 2.198766382031054 Accuracy: 0.3403430451127819\n",
      "Epoch 4 Loss: 2.2113725036266474 Accuracy: 0.31414473684210525\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91391892f7834d95b45d3a39a8fcb921",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7babe7bc564ef89c0f7f08c85e417f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.184139014196132 Accuracy: 0.3202537593984962\n",
      "Epoch 1 Loss: 2.1895564459637464 Accuracy: 0.28888627819548873\n",
      "Epoch 2 Loss: 2.207876581508109 Accuracy: 0.3335291353383459\n",
      "Epoch 3 Loss: 2.1896363826447343 Accuracy: 0.30968045112781956\n",
      "Epoch 4 Loss: 2.192962999676383 Accuracy: 0.31778665413533835\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f894216add404401bb58a9ad33ba3af8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be4b13efec864b178281b9734ae4478f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.1825100777964765 Accuracy: 0.3246005639097745\n",
      "Epoch 1 Loss: 2.2214083073757256 Accuracy: 0.2999295112781955\n",
      "Epoch 2 Loss: 2.174347365309355 Accuracy: 0.2933505639097745\n",
      "Epoch 3 Loss: 2.164408434883566 Accuracy: 0.33658364661654133\n",
      "Epoch 4 Loss: 2.1841465009743297 Accuracy: 0.31708176691729323\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2c840c0bf8944d8bf21c41d4696b6a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebcd513524c0469b85333a29fccf95d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.1701436121107966 Accuracy: 0.32554041353383456\n",
      "Epoch 1 Loss: 2.1607182860242764 Accuracy: 0.30991541353383456\n",
      "Epoch 2 Loss: 2.183658727402833 Accuracy: 0.3075657894736842\n",
      "Epoch 3 Loss: 2.175092256919081 Accuracy: 0.31414473684210525\n",
      "Epoch 4 Loss: 2.160529346605323 Accuracy: 0.3059210526315789\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32139e1e1bc149dba45d1c7f96e46b99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a097d8e72e7b4388825fce8b11f8cfed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.170828030045657 Accuracy: 0.3179041353383459\n",
      "Epoch 1 Loss: 2.1607077928943537 Accuracy: 0.30838815789473684\n",
      "Epoch 2 Loss: 2.1602443740243347 Accuracy: 0.321781015037594\n",
      "Epoch 3 Loss: 2.147678154176353 Accuracy: 0.29699248120300753\n",
      "Epoch 4 Loss: 2.158146634421969 Accuracy: 0.3402255639097745\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80511a1781754b7ea505c1564878bed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da44faaeec264437ae556fa4c980f253",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.1469263409374304 Accuracy: 0.32307330827067665\n",
      "Epoch 1 Loss: 2.1638216985084773 Accuracy: 0.30968045112781956\n",
      "Epoch 2 Loss: 2.165678381832978 Accuracy: 0.3142622180451128\n",
      "Epoch 3 Loss: 2.1547134396183725 Accuracy: 0.3261278195488722\n",
      "Epoch 4 Loss: 2.1354504810078674 Accuracy: 0.32013627819548873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aadfe81e6dc4aca8386a204f0eb2511",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4010435823444e0ba72678ad30bb60dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.161569025261341 Accuracy: 0.3223684210526316\n",
      "Epoch 1 Loss: 2.135560915611855 Accuracy: 0.3142622180451128\n",
      "Epoch 2 Loss: 2.152059706611594 Accuracy: 0.3194313909774436\n",
      "Epoch 3 Loss: 2.1371653708678364 Accuracy: 0.33670112781954886\n",
      "Epoch 4 Loss: 2.152288225883005 Accuracy: 0.2926456766917293\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c418ea85db94bddbf353996bb2d8150",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 8\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db088d79b3c3465db0a4bbbf269740c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.1314382329177093 Accuracy: 0.3202537593984962\n",
      "Epoch 1 Loss: 2.1416687659149103 Accuracy: 0.30979793233082703\n",
      "Epoch 2 Loss: 2.1464970909448575 Accuracy: 0.3089755639097745\n",
      "Epoch 3 Loss: 2.1548789478067953 Accuracy: 0.32248590225563906\n",
      "Epoch 4 Loss: 2.170156174901963 Accuracy: 0.3022791353383459\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3602a23a730f4c9ab23680733b78439f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a3f40133842e4c6d92e5e7b7e01486f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.1223247338336413 Accuracy: 0.33905075187969924\n",
      "Epoch 1 Loss: 2.1372277571527376 Accuracy: 0.3343515037593985\n",
      "Epoch 2 Loss: 2.151345595246096 Accuracy: 0.3314144736842105\n",
      "Epoch 3 Loss: 2.1441203254217953 Accuracy: 0.3238956766917293\n",
      "Epoch 4 Loss: 2.1346801396337574 Accuracy: 0.3329417293233083\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56f0201c2348490287710542ca887127",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 10\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2dd11b9efa4581926aa2d0b361da18",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.1263574404721655 Accuracy: 0.3179041353383459\n",
      "Epoch 1 Loss: 2.144711940414941 Accuracy: 0.33129699248120303\n",
      "Epoch 2 Loss: 2.128009689632761 Accuracy: 0.3202537593984962\n",
      "Epoch 3 Loss: 2.136937802693059 Accuracy: 0.32095864661654133\n",
      "Epoch 4 Loss: 2.1424382361274197 Accuracy: 0.31860902255639095\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f55d70790d0343b6bff9cda84246ce6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 11\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a10c3382f7479fb974c3df8e423380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.1279645565956464 Accuracy: 0.33211936090225563\n",
      "Epoch 1 Loss: 2.143449914017214 Accuracy: 0.32013627819548873\n",
      "Epoch 2 Loss: 2.1287937652015634 Accuracy: 0.2948778195488722\n",
      "Epoch 3 Loss: 2.13448316255433 Accuracy: 0.3223684210526316\n",
      "Epoch 4 Loss: 2.1455817733670797 Accuracy: 0.31802161654135336\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a7134d72d074578a5cbf17058c81d99",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 12\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22df49b2f3f24181822a45f55a9bdd25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.117063327369797 Accuracy: 0.3223684210526316\n",
      "Epoch 1 Loss: 2.1194143816117985 Accuracy: 0.31802161654135336\n",
      "Epoch 2 Loss: 2.123504705030452 Accuracy: 0.3284774436090226\n",
      "Epoch 3 Loss: 2.136569791118092 Accuracy: 0.3231907894736842\n",
      "Epoch 4 Loss: 2.1255880295013734 Accuracy: 0.32835996240601506\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85e2ed015e73447c80780ff9677886e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0429ebdc8fd499bbc024fc7a6f5bc3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.1355559447267227 Accuracy: 0.3260103383458647\n",
      "Epoch 1 Loss: 2.1162860126779264 Accuracy: 0.32248590225563906\n",
      "Epoch 2 Loss: 2.1260666354176228 Accuracy: 0.34480733082706766\n",
      "Epoch 3 Loss: 2.1165875685131588 Accuracy: 0.3275375939849624\n",
      "Epoch 4 Loss: 2.1261168680163474 Accuracy: 0.3246005639097745\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8953e2a80c5f42c0afe621fbed2f309a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a9c90942c1146749cbc75e530b5cc2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.1055679698979755 Accuracy: 0.32918233082706766\n",
      "Epoch 1 Loss: 2.127721020566212 Accuracy: 0.3305921052631579\n",
      "Epoch 2 Loss: 2.109849709298739 Accuracy: 0.32835996240601506\n",
      "Epoch 3 Loss: 2.1221116923788808 Accuracy: 0.3215460526315789\n",
      "Epoch 4 Loss: 2.098963934208392 Accuracy: 0.3359962406015038\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc03b577d3d644688805c9839c68acff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7b59746f7b9411abf639935a5bbfe2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.122218351066678 Accuracy: 0.3418703007518797\n",
      "Epoch 1 Loss: 2.101587059898683 Accuracy: 0.3314144736842105\n",
      "Epoch 2 Loss: 2.127455045383433 Accuracy: 0.33129699248120303\n",
      "Epoch 3 Loss: 2.121809659411486 Accuracy: 0.32765507518796994\n",
      "Epoch 4 Loss: 2.116575289765836 Accuracy: 0.3305921052631579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5c7d23bccf1b461f87d8b6654cc1f8a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 16\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c137f52ea47a47849719db2e80f97e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0997663450143373 Accuracy: 0.33517387218045114\n",
      "Epoch 1 Loss: 2.1117861588031377 Accuracy: 0.3402255639097745\n",
      "Epoch 2 Loss: 2.1005239660423807 Accuracy: 0.33658364661654133\n",
      "Epoch 3 Loss: 2.115635168787841 Accuracy: 0.32307330827067665\n",
      "Epoch 4 Loss: 2.0895260883358753 Accuracy: 0.3305921052631579\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8897c3816f614adaa176b35918cbbffb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 17\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2733cf12177c441cbad116f0bbbfb228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.091873448656549 Accuracy: 0.33211936090225563\n",
      "Epoch 1 Loss: 2.0944367054985484 Accuracy: 0.3350563909774436\n",
      "Epoch 2 Loss: 2.1030479204655754 Accuracy: 0.3388157894736842\n",
      "Epoch 3 Loss: 2.0894734784354787 Accuracy: 0.3202537593984962\n",
      "Epoch 4 Loss: 2.12131262526243 Accuracy: 0.33728853383458646\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "977c4ae6bf96481da7aec247ebbbc6ef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 18\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd9c837bcf29435b8fc5fe69dfbe9ebf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.1117348810121075 Accuracy: 0.3388157894736842\n",
      "Epoch 1 Loss: 2.0904115407569233 Accuracy: 0.33364661654135336\n",
      "Epoch 2 Loss: 2.114830630464874 Accuracy: 0.32976973684210525\n",
      "Epoch 3 Loss: 2.095466418462128 Accuracy: 0.33576127819548873\n",
      "Epoch 4 Loss: 2.1058527896886705 Accuracy: 0.32248590225563906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44cc39e10be14560b389adfc49f0444e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "623a9b73567049c0951b7fadd5569464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.090523397024569 Accuracy: 0.33658364661654133\n",
      "Epoch 1 Loss: 2.111423903362557 Accuracy: 0.32976973684210525\n",
      "Epoch 2 Loss: 2.092232691673181 Accuracy: 0.3388157894736842\n",
      "Epoch 3 Loss: 2.114977279994289 Accuracy: 0.33576127819548873\n",
      "Epoch 4 Loss: 2.092291939223579 Accuracy: 0.33129699248120303\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c07725b3967f4af2acf19ba0d6e05dc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 20\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2adbe867d7b84b3287be817122b57534",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.073858909011604 Accuracy: 0.33963815789473684\n",
      "Epoch 1 Loss: 2.0839295539121867 Accuracy: 0.3304746240601504\n",
      "Epoch 2 Loss: 2.1058036039439423 Accuracy: 0.3388157894736842\n",
      "Epoch 3 Loss: 2.08610729664999 Accuracy: 0.33658364661654133\n",
      "Epoch 4 Loss: 2.0664792583920453 Accuracy: 0.34786184210526316\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3607db078e39431c9d750ecce903c27f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 21\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d8cabf6531d45e3acda05bda244c762",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0939414818136486 Accuracy: 0.33270676691729323\n",
      "Epoch 1 Loss: 2.0783863820912982 Accuracy: 0.3246005639097745\n",
      "Epoch 2 Loss: 2.0827532425216924 Accuracy: 0.3395206766917293\n",
      "Epoch 3 Loss: 2.06772679693116 Accuracy: 0.33963815789473684\n",
      "Epoch 4 Loss: 2.0931804963925047 Accuracy: 0.34104793233082703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8367b8dd96044f9c8a4ac867b25d3595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 22\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70c66f6d9e9f4bf3804cfe4d309952f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.096863443375596 Accuracy: 0.3215460526315789\n",
      "Epoch 1 Loss: 2.0839893894120025 Accuracy: 0.33576127819548873\n",
      "Epoch 2 Loss: 2.0932792830500073 Accuracy: 0.33658364661654133\n",
      "Epoch 3 Loss: 2.0950001892663557 Accuracy: 0.33658364661654133\n",
      "Epoch 4 Loss: 2.068514685239983 Accuracy: 0.3417528195488722\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a5f20111e4b4d7592d3b79cb5f4eeee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 23\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc597c3da6184f608ead743d67e701a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0682799380793115 Accuracy: 0.3364661654135338\n",
      "Epoch 1 Loss: 2.0670302544275576 Accuracy: 0.3404605263157895\n",
      "Epoch 2 Loss: 2.10738986681864 Accuracy: 0.3379934210526316\n",
      "Epoch 3 Loss: 2.0706751570039903 Accuracy: 0.34398496240601506\n",
      "Epoch 4 Loss: 2.063698236570644 Accuracy: 0.34480733082706766\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae2def9bf67d4a79b1fcc37235cbb531",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 24\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48ba0d0b6f2944e0b58876bd48833f8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0879226468279612 Accuracy: 0.3485667293233083\n",
      "Epoch 1 Loss: 2.0686411177633195 Accuracy: 0.3379934210526316\n",
      "Epoch 2 Loss: 2.0702466280057576 Accuracy: 0.34927161654135336\n",
      "Epoch 3 Loss: 2.0635405495499555 Accuracy: 0.3418703007518797\n",
      "Epoch 4 Loss: 2.065495427828611 Accuracy: 0.3417528195488722\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "672a6452e7af4c56b7b985cb6d352400",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 25\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a723a9b9fd2f4df2aa0e2c265d7cd602",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0883086166359752 Accuracy: 0.33728853383458646\n",
      "Epoch 1 Loss: 2.060496949844076 Accuracy: 0.3576127819548872\n",
      "Epoch 2 Loss: 2.059538074497372 Accuracy: 0.3515037593984962\n",
      "Epoch 3 Loss: 2.0710703867739246 Accuracy: 0.3446898496240602\n",
      "Epoch 4 Loss: 2.0742786093263845 Accuracy: 0.3402255639097745\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d9b776c6a3d40e5894b41a09e38e811",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 26\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e91469e6a65412d86bd0c9efaaf47c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0713556650806964 Accuracy: 0.34927161654135336\n",
      "Epoch 1 Loss: 2.060914535670615 Accuracy: 0.34257518796992475\n",
      "Epoch 2 Loss: 2.076786550151501 Accuracy: 0.34328007518796994\n",
      "Epoch 3 Loss: 2.0777520331524073 Accuracy: 0.3460996240601504\n",
      "Epoch 4 Loss: 2.0602777011170237 Accuracy: 0.36207706766917297\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "77c5990b9427410f965e2b60b708e791",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 27\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09c843d3964b47c0b5de61066ff2f059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.072871604086314 Accuracy: 0.34398496240601506\n",
      "Epoch 1 Loss: 2.055340562455064 Accuracy: 0.3491541353383459\n",
      "Epoch 2 Loss: 2.0599906490507007 Accuracy: 0.3491541353383459\n",
      "Epoch 3 Loss: 2.066268912621215 Accuracy: 0.3499765037593985\n",
      "Epoch 4 Loss: 2.0523574373587263 Accuracy: 0.3470394736842105\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "954711043aab49ffa7f9392a7750149b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "097024fe2ee24cf0acbfb5b01bd6b35f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0811004272003544 Accuracy: 0.34844924812030076\n",
      "Epoch 1 Loss: 2.044342498553121 Accuracy: 0.36348684210526316\n",
      "Epoch 2 Loss: 2.078814185404672 Accuracy: 0.3506813909774436\n",
      "Epoch 3 Loss: 2.0689420137724794 Accuracy: 0.34245770676691734\n",
      "Epoch 4 Loss: 2.0494006499419517 Accuracy: 0.35138627819548873\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3000cf1e5c894c018b2188b796392290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 29\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb1ac7b9f4084a70a97c94ac00cc886e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0523284253888066 Accuracy: 0.36043233082706766\n",
      "Epoch 1 Loss: 2.043809276421759 Accuracy: 0.3618421052631579\n",
      "Epoch 2 Loss: 2.0475721458123246 Accuracy: 0.35960996240601506\n",
      "Epoch 3 Loss: 2.046370942013758 Accuracy: 0.3455122180451128\n",
      "Epoch 4 Loss: 2.040369143621566 Accuracy: 0.35232612781954886\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb87f96d7da146db94b19224dca82e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 30\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ba811fd719342dcb4a68d3fb9af2f6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0622461686026496 Accuracy: 0.3476268796992481\n",
      "Epoch 1 Loss: 2.0411601487841464 Accuracy: 0.3491541353383459\n",
      "Epoch 2 Loss: 2.0588676995491353 Accuracy: 0.35291353383458646\n",
      "Epoch 3 Loss: 2.052293416337375 Accuracy: 0.36043233082706766\n",
      "Epoch 4 Loss: 2.0392133899203873 Accuracy: 0.35667293233082703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c16f152f6dd46f98f0c19d9fcb0d094",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 31\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53c2e88a4b9b4a4f84dd6585db64a84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0454444407777754 Accuracy: 0.3544407894736842\n",
      "Epoch 1 Loss: 2.0601844460290417 Accuracy: 0.3520911654135338\n",
      "Epoch 2 Loss: 2.0426525594871596 Accuracy: 0.35820018796992475\n",
      "Epoch 3 Loss: 2.046205035061639 Accuracy: 0.3731203007518797\n",
      "Epoch 4 Loss: 2.0562962458496155 Accuracy: 0.35432330827067665\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0c69577baa646ca87a2e4c85ac64db7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93c2d78972e24ea9b3661b60f94bc102",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.055373475539082 Accuracy: 0.34844924812030076\n",
      "Epoch 1 Loss: 2.054365951537099 Accuracy: 0.3544407894736842\n",
      "Epoch 2 Loss: 2.037850274605899 Accuracy: 0.3641917293233083\n",
      "Epoch 3 Loss: 2.0574461469986853 Accuracy: 0.37605733082706766\n",
      "Epoch 4 Loss: 2.061356033730212 Accuracy: 0.3656015037593985\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70b15ea79dc948baae1c4943c278d53f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 33\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2c21871427a49c6970b4a00982049c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.048843833590992 Accuracy: 0.34386748120300753\n",
      "Epoch 1 Loss: 2.0505189004168445 Accuracy: 0.35808270676691734\n",
      "Epoch 2 Loss: 2.0489459475796887 Accuracy: 0.35138627819548873\n",
      "Epoch 3 Loss: 2.037978366800344 Accuracy: 0.3731203007518797\n",
      "Epoch 4 Loss: 2.0566888241927685 Accuracy: 0.3573778195488722\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b25c065473b4ad3b7bc8d61b4bca2db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 34\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20e0b0925d4c489cb01da6970f7f9a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.04929889132963 Accuracy: 0.3558505639097745\n",
      "Epoch 1 Loss: 2.0337675265995574 Accuracy: 0.35960996240601506\n",
      "Epoch 2 Loss: 2.027023010889855 Accuracy: 0.36783364661654133\n",
      "Epoch 3 Loss: 2.035982911269033 Accuracy: 0.3677161654135338\n",
      "Epoch 4 Loss: 2.03500106961389 Accuracy: 0.35820018796992475\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02e9993214b44873a42f89276a2396b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 35\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df927c9cc7e2473091ec7636a2ec40ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0543418253765293 Accuracy: 0.36407424812030076\n",
      "Epoch 1 Loss: 2.03106810722651 Accuracy: 0.36336936090225563\n",
      "Epoch 2 Loss: 2.0374653638017888 Accuracy: 0.35808270676691734\n",
      "Epoch 3 Loss: 2.0452184184603994 Accuracy: 0.35291353383458646\n",
      "Epoch 4 Loss: 2.0206332287653272 Accuracy: 0.36336936090225563\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53d35f991f014d0bbe3c2c0f8655b063",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 36\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec49aa95852f4a0fab84764f7be8c723",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0487885705051485 Accuracy: 0.3692434210526316\n",
      "Epoch 1 Loss: 2.0339734886391962 Accuracy: 0.3715930451127819\n",
      "Epoch 2 Loss: 2.040768366209077 Accuracy: 0.368656015037594\n",
      "Epoch 3 Loss: 2.023688801432628 Accuracy: 0.3618421052631579\n",
      "Epoch 4 Loss: 2.0311465983541974 Accuracy: 0.37229793233082703\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5f7387f535544deb8ba11b6dd3d1f7a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 37\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58817c146d9f4a00b0b760b5786c49f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0273440125350546 Accuracy: 0.3617246240601504\n",
      "Epoch 1 Loss: 2.0350204179748106 Accuracy: 0.37605733082706766\n",
      "Epoch 2 Loss: 2.0187516457228023 Accuracy: 0.3603148496240602\n",
      "Epoch 3 Loss: 2.0408711822291496 Accuracy: 0.3730028195488722\n",
      "Epoch 4 Loss: 2.030934801944762 Accuracy: 0.38345864661654133\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b4b4a466aa4decaf504b010bb1787c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 38\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "308bdd25c7464b4486e5f68122b59f13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.032715538277183 Accuracy: 0.36336936090225563\n",
      "Epoch 1 Loss: 2.003299608398646 Accuracy: 0.37100563909774437\n",
      "Epoch 2 Loss: 2.0191573857605607 Accuracy: 0.3632518796992481\n",
      "Epoch 3 Loss: 2.016478473471342 Accuracy: 0.3700657894736842\n",
      "Epoch 4 Loss: 2.0300156134894443 Accuracy: 0.3767622180451128\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c33eca82c6946d08ce2e1c2c8838521",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 39\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "223044fb91bf449593d67a3923f2c6d2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0116766740458574 Accuracy: 0.3701832706766917\n",
      "Epoch 1 Loss: 2.0091440196711585 Accuracy: 0.35890507518796994\n",
      "Epoch 2 Loss: 2.0048968924508745 Accuracy: 0.37218045112781956\n",
      "Epoch 3 Loss: 1.9956001873073184 Accuracy: 0.3828712406015038\n",
      "Epoch 4 Loss: 2.0200879765800424 Accuracy: 0.38052161654135336\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bbd5d3dcb74c3c8f6e9ddf30a18324",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_num 40\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30d3a6e7b38c4a7a9fae4b606292da7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 Loss: 2.0579282199390616 Accuracy: 0.3527960526315789\n",
      "Epoch 1 Loss: 2.0274289097093083 Accuracy: 0.3661889097744361\n",
      "Epoch 2 Loss: 2.0269586823709274 Accuracy: 0.3656015037593985\n",
      "Epoch 3 Loss: 2.0152324301579774 Accuracy: 0.3663063909774436\n",
      "Epoch 4 Loss: 2.002226998084028 Accuracy: 0.3700657894736842\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b694b52155ad442293e6a2e1333cc93a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for dataset_num in range(len(df_train)):\n",
    "    print(\"dataset_num\", dataset_num)\n",
    "    df = df_train[dataset_num]\n",
    "\n",
    "    class_values_era = list(df.era.unique())\n",
    "    class_values_era.sort()\n",
    "    class_values_target = list(df.target_10_val.unique())\n",
    "    class_values_target.sort()\n",
    "    era_encoding = {val: i for i, val in enumerate(class_values_era)}\n",
    "    target_encoding = {val: i for i, val in enumerate(class_values_target)}\n",
    "    df[\"era\"] = df[\"era\"].apply(encode, args=(era_encoding,))\n",
    "    df[\"target_5_val\"] = df[\"target_5_val\"].apply(encode, args=(target_encoding,))\n",
    "    df[\"target_10_val\"] = df[\"target_10_val\"].apply(encode, args=(target_encoding,))\n",
    "\n",
    "    dataset = df\n",
    "    target_column = \"target_10_val\"\n",
    "    output_classes = 5\n",
    "    shuffle = True\n",
    "\n",
    "    train_dataset = CustomDataset(new_dataset.drop(columns=[target_column,'era','row_num']).values, new_dataset[target_column].values)\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=shuffle)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    epochs = 5\n",
    "    losses = []\n",
    "    predictions = []\n",
    "    accuracy = []\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        # loop = tqdm(train_loader, leave=True)\n",
    "        epoch_acc=[]\n",
    "        epoch_loss=[]\n",
    "        for batch,(X, y) in enumerate(train_loader):\n",
    "            X, y = X.cuda().float(), y.cuda().long()\n",
    "            \n",
    "            # # mask 5 columns in X\n",
    "            # mask = torch.randint(0, 27, (5,))\n",
    "            # X[:, mask] = 0\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            prediction_logits, auxiliary,tau = model(X)\n",
    "            # print(tau)\n",
    "            prediction_softmax = F.softmax(prediction_logits, dim=1).to(torch.float64)\n",
    "            prediction = torch.argmax(prediction_softmax, dim=1)\n",
    "\n",
    "            loss1 = classification_criterion(prediction_softmax, y,tau)\n",
    "            # print(prediction_logits)\n",
    "            loss2 = auxiliary_criterion(auxiliary, X)\n",
    "            # print(loss1.item(), loss2.item()    )\n",
    "            accuracy_batch = (prediction == y).sum().item() / len(y)\n",
    "            epoch_acc.append(accuracy_batch)\n",
    "\n",
    "            loss = loss1 + loss2\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            # losses.append(loss.item())\n",
    "            epoch_loss.append(loss.item())\n",
    "            predictions.append(prediction)\n",
    "            # break\n",
    "            # if batch == bagging_percent * len(train_loader):\n",
    "            #     break\n",
    "        accuracy.append(np.mean(epoch_acc))\n",
    "        losses.append(np.mean(epoch_loss))\n",
    "        print(f\"Epoch {epoch} Loss: {np.mean(epoch_loss)} Accuracy: {np.mean(epoch_acc)}\")\n",
    "\n",
    "\n",
    "    df_test_list = df_test[dataset_num]\n",
    "    target_column = \"row_num\"\n",
    "    output_classes = 5\n",
    "\n",
    "    test_dataset = CustomDataset(df_test_list.drop(columns=[target_column,'row_num','id']).values, df_test_list[target_column].values)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "    # test the model on test data\n",
    "    test_accuracies = []\n",
    "    predictions=[]\n",
    "    all_prediction_logits = []\n",
    "\n",
    "    for batch, (X,y) in tqdm(enumerate((test_loader))):\n",
    "        optimizer.zero_grad()\n",
    "        X, y = X,y\n",
    "        X,y= X.cuda().float(), y.cuda().long()\n",
    "        prediction_logits, auxiliary,tau = model(X)\n",
    "\n",
    "        aux_loss = auxiliary_criterion(auxiliary, X)\n",
    "        loss = aux_loss\n",
    "        # print(\"aux_loss\", aux_loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        prediction_logits, auxiliary,tau = model(X)\n",
    "        prediction = F.softmax(prediction_logits, dim=1)\n",
    "        prediction = torch.argmax(prediction, dim=1)\n",
    "        all_prediction_logits.extend(prediction)\n",
    "        # batch_accuracy = (prediction == y).sum().item() / len(y)\n",
    "        # test_accuracies.append(batch_accuracy)\n",
    "        predictions.append(prediction.item())\n",
    "\n",
    "        if batch == 10:\n",
    "            break\n",
    "    all_predictions.append(predictions)\n",
    "    # print(f\"Test Accuracy: {np.mean(test_accuracies)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[3],\n",
       " [4, 2, 2, 4, 4, 3, 4, 2, 4, 3],\n",
       " [4, 2, 2, 4, 4, 3, 4, 2, 4, 2],\n",
       " [4, 2, 4],\n",
       " [3, 4],\n",
       " [4, 4],\n",
       " [4, 4],\n",
       " [4, 4],\n",
       " [4, 4],\n",
       " [4, 4],\n",
       " [2, 4],\n",
       " [4],\n",
       " [4, 4, 2, 4, 4, 4, 2],\n",
       " [2, 2, 4, 4],\n",
       " [4, 2],\n",
       " [2],\n",
       " [4, 2, 4, 2],\n",
       " [4, 2, 4],\n",
       " [4, 4, 2, 4, 4, 4],\n",
       " [4, 2, 4, 2, 4, 4, 4],\n",
       " [4, 4, 4, 2, 4, 4],\n",
       " [4, 4, 4, 2, 4],\n",
       " [4, 4, 4, 2],\n",
       " [4, 2],\n",
       " [4, 2],\n",
       " [2, 4, 2],\n",
       " [4, 2],\n",
       " [2, 4, 2],\n",
       " [2],\n",
       " [4, 4],\n",
       " [4],\n",
       " [4, 4],\n",
       " [4, 4, 4],\n",
       " [4, 4, 4, 4, 4],\n",
       " [4, 4, 4, 4, 4],\n",
       " [4, 4, 4, 4],\n",
       " [4, 4, 4],\n",
       " [4, 4, 4],\n",
       " [2, 2, 4, 4, 2],\n",
       " [2, 4, 2, 4, 4, 2],\n",
       " [4, 4, 2, 4, 4, 4, 2]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save predictions to a file\n",
    "import csv\n",
    "with open('5Apr_predictions.csv', 'w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerows(all_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nums(folder):\n",
    "    count = 0\n",
    "    files = sort_files(folder)\n",
    "    row_nums = []\n",
    "    round_nums = []\n",
    "    ids = []\n",
    "    for file in files:\n",
    "        if file[0:12] == 'df_live_test':\n",
    "            count+=1\n",
    "            if file[-7] == '_':\n",
    "                round_nums.append(file[-6:-4])\n",
    "            else:\n",
    "                round_nums.append(file[-7:-4])\n",
    "            \n",
    "            file_path = os.path.join(folder, file)\n",
    "            df_temp = pd.read_csv(file_path)\n",
    "            row_nums.extend(df_temp.row_num.values)\n",
    "            ids.extend(df_temp.id.values)\n",
    "\n",
    "    return round_nums, row_nums, ids\n",
    "\n",
    "days = [2, 3, 4, 5, 8]\n",
    "\n",
    "for x in days:\n",
    "    predictions = []\n",
    "    with open(f'predictions/{x}Apr_predictions.csv', 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        for row in reader:\n",
    "            predictions.append(row)\n",
    "\n",
    "    predictions = [x for x in predictions if x != []]\n",
    "    folder = f'live_data/live_data_0{x}-Apr-2024'\n",
    "\n",
    "    round_nums, row_nums, ids = get_nums(folder)\n",
    "    all_predictions = []\n",
    "    all_round_nums = []\n",
    "\n",
    "    for prediction in predictions:\n",
    "        all_predictions.extend(prediction)\n",
    "        \n",
    "    for i in range(len(predictions)):\n",
    "        for j in range(len(predictions[i])):\n",
    "            all_round_nums.append(round_nums[i])\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    df['id'] = ids\n",
    "    df['prediction'] = all_predictions\n",
    "    df['row_num'] = row_nums\n",
    "    df['round_num'] = all_round_nums\n",
    "\n",
    "    df.to_csv(f'final_predictions/predictions_0{x}-04-2024.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
